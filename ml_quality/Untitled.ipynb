{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sklearn\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good = open(\"../scripts/codestyle_stats/fine_res.json\", \"r\")\n",
    "bad = open(\"../scripts/codestyle_stats/shit_res.json\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_data = bad.read().replace('\\n', ' ')\n",
    "bad_dict = json.loads(bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_data = good.read().replace('\\n', ' ')\n",
    "good_dict = json.loads(good_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n"
     ]
    }
   ],
   "source": [
    "print len(bad_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540\n"
     ]
    }
   ],
   "source": [
    "print len(good_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'E901': 0, u'E227': 0, u'E721': 0, u'W604': 0, u'W603': 0, u'W602': 0, u'W601': 0, u'E224': 0, u'W503': 0, u'E101': 0, u'E501': 0, u'E711': 0, u'E201': 0, u'E203': 0, u'E202': 0, u'E128': 0, u'E129': 0, u'E124': 0, u'E125': 0, u'E126': 0, u'E127': 0, u'E121': 0, u'E122': 0, u'E123': 0, u'E266': 0, u'E265': 0, u'E228': 0, u'E402': 0, u'E261': 0, u'E223': 0, u'E222': 0, u'E302': 0, u'E303': 0, u'E304': 0, u'E226': 0, u'E306': 0, u'E262': 0, u'E401': 0, u'E701': 0, u'E221': 0, u'E115': 0, u'E114': 0, u'E116': 0, u'E111': 0, u'E113': 0, u'E112': 0, u'E731': 0, u'E271': 0, u'E305': 0, u'E241': 0, u'W291': 0, u'E714': 0, u'E301': 0, u'W293': 5, u'E211': 0, u'E713': 0, u'E502': 0, u'E131': 0, u'E712': 0, u'E274': 0, u'E275': 0, u'E251': 0, u'E225': 0, u'E272': 0, u'E273': 0, u'E704': 0, u'E231': 0, u'E242': 0, u'E191': 0, u'E722': 0, u'E702': 0, u'E703': 0}\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6355a1d20e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mbad_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"errors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for i in (1, len(bad_dict)):\n",
    "    print bad_dict[i][\"errors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(input_var=None):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 1, 78),\n",
    "                                     input_var=input_var)\n",
    "    \n",
    "    l_in_drop = lasagne.layers.DropoutLayer(l_in, p = 0.2)\n",
    "    \n",
    "    l_hid = lasagne.layers.DenseLayer(l_in_drop, num_units=80, \n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                       W=lasagne.init.GlorotUniform())\n",
    "    l_out = lasagne.layers.DenseLayer(l_hid, num_units=2, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var = T.tensor3('inputs')\n",
    "target_var = T.ivector('targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = build_network(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, \n",
    "                                                   target_var)\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params,\n",
    "                                            learning_rate=0.01,\n",
    "                                            momentum=0.9)\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(\n",
    "                                                    test_prediction,\n",
    "                                                    target_var)\n",
    "test_loss = test_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var], loss,\n",
    "                           updates=updates)\n",
    "val_fn = theano.function([input_var, target_var], test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(500):\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 100, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        train_batches += 1\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 100, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    print train_err / train_batches\n",
    "    print val_err / val_batches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
