{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flerchy/.virtualenvs/ml/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import sklearn\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import lasagne.regularization as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good = open(\"../scripts/codestyle_stats/fine_res.json\", \"r\")\n",
    "bad = open(\"../scripts/codestyle_stats/shit_res.json\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_data = bad.read().replace('\\n', ' ')\n",
    "bad_dict = json.loads(bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_data = good.read().replace('\\n', ' ')\n",
    "good_dict = json.loads(good_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n"
     ]
    }
   ],
   "source": [
    "print len(bad_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print len(good_dict)\n",
    "print [0]*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 82)\n"
     ]
    }
   ],
   "source": [
    "bad = []\n",
    "for i in range(0, len(bad_dict)):\n",
    "    s = []\n",
    "    if ('errors' in bad_dict[i]):\n",
    "        #print bad_dict[i]['errors']\n",
    "        s.extend(bad_dict[i]['errors'].values())\n",
    "        #print s\n",
    "    else:\n",
    "        s.extend([0]*(len(bad_dict[0]['errors'])))\n",
    "    #print s\n",
    "    #print s\n",
    "    for key, value in bad_dict[i].items():\n",
    "         if key not in ('errors', 'filename'):\n",
    "            s.append(int(value))\n",
    "    #print data\n",
    "    s =numpy.array(s) \n",
    "    bad.append(s)\n",
    "bad = numpy.array(bad)\n",
    "print bad.shape\n",
    "# for i in range(0, len(X_train)):\n",
    "#     for elem in X_train[i]:\n",
    "#         if not (isinstance( elem, int )):\n",
    "#             print i\n",
    "#             print type(elem)\n",
    "#print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 82)\n"
     ]
    }
   ],
   "source": [
    "print bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 82)\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  1  0 17  0  0]\n"
     ]
    }
   ],
   "source": [
    "good = []\n",
    "for i in range(0, len(bad_dict)):\n",
    "    s = []\n",
    "    if ('errors' in good_dict[i]):\n",
    "        #print bad_dict[i]['errors']\n",
    "        s.extend(numpy.array(good_dict[i]['errors'].values()))\n",
    "        #print s\n",
    "    else:\n",
    "        s.extend([0]*(len(bad_dict[0]['errors'])))\n",
    "    #print s\n",
    "    #print s\n",
    "    for key, value in good_dict[i].items():\n",
    "         if key not in ('errors', 'filename'):\n",
    "            s.append(int(value))\n",
    "            #print data\n",
    "    s = numpy.array(s)\n",
    "    good.append(s)\n",
    "good = numpy.array(good)\n",
    "print good.shape\n",
    "print good[0]\n",
    "    #print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1216, 82)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "X_train.extend(good)\n",
    "X_train.extend(bad)\n",
    "X_train = numpy.array(X_train)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = numpy.array([1]*len(bad_dict) + [0]* len(bad_dict), dtype=numpy.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 82)\n",
      "(487, 82)\n",
      "(729,)\n",
      "(487,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4)\n",
    "for s in (X_train, X_val, y_train, y_val):\n",
    "    print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729,)\n"
     ]
    }
   ],
   "source": [
    "print numpy.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 82)\n"
     ]
    }
   ],
   "source": [
    "print numpy.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(input_var=None):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 82),\n",
    "                                     input_var=input_var)\n",
    "    l_hid = lasagne.layers.DenseLayer(l_in, num_units=82, \n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                       W=lasagne.init.GlorotUniform())\n",
    "    l_hid2 = lasagne.layers.DenseLayer(l_hid, num_units=20, \n",
    "                                       nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                       W=lasagne.init.GlorotUniform())\n",
    "    l_out = lasagne.layers.DenseLayer(l_hid2, num_units=2, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    #print inputs\n",
    "    #print targets\n",
    "    if shuffle:\n",
    "        indices = numpy.arange(len(inputs))\n",
    "        numpy.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.matrix('inputs')\n",
    "target_var = T.ivector('targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = build_network(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params,\n",
    "                                            learning_rate=0.01,\n",
    "                                            momentum=0.9)\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(\n",
    "                                                    test_prediction,\n",
    "                                                    target_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.696622\n",
      "  validation loss:\t\t0.686107\n",
      "  validation accuracy:\t\t64.67 %\n",
      "  training loss:\t\t0.686012\n",
      "  validation loss:\t\t0.690249\n",
      "  validation accuracy:\t\t54.00 %\n",
      "  training loss:\t\t0.690218\n",
      "  validation loss:\t\t0.691176\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.690250\n",
      "  validation loss:\t\t0.690389\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.689126\n",
      "  validation loss:\t\t0.688862\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.688184\n",
      "  validation loss:\t\t0.687459\n",
      "  validation accuracy:\t\t54.89 %\n",
      "  training loss:\t\t0.686020\n",
      "  validation loss:\t\t0.683597\n",
      "  validation accuracy:\t\t56.00 %\n",
      "  training loss:\t\t0.678527\n",
      "  validation loss:\t\t0.683847\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.682352\n",
      "  validation loss:\t\t0.693349\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.692231\n",
      "  validation loss:\t\t0.692728\n",
      "  validation accuracy:\t\t50.44 %\n",
      "  training loss:\t\t0.691778\n",
      "  validation loss:\t\t0.691020\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691431\n",
      "  validation loss:\t\t0.690559\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.691262\n",
      "  validation loss:\t\t0.690962\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691662\n",
      "  validation loss:\t\t0.690584\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.690649\n",
      "  validation loss:\t\t0.690151\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.690192\n",
      "  validation loss:\t\t0.689371\n",
      "  validation accuracy:\t\t53.11 %\n",
      "  training loss:\t\t0.688999\n",
      "  validation loss:\t\t0.689246\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.690858\n",
      "  validation loss:\t\t0.689377\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.687517\n",
      "  validation loss:\t\t0.686055\n",
      "  validation accuracy:\t\t56.00 %\n",
      "  training loss:\t\t0.685778\n",
      "  validation loss:\t\t0.684089\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.681963\n",
      "  validation loss:\t\t0.672150\n",
      "  validation accuracy:\t\t65.11 %\n",
      "  training loss:\t\t0.674431\n",
      "  validation loss:\t\t0.676175\n",
      "  validation accuracy:\t\t59.11 %\n",
      "  training loss:\t\t0.677649\n",
      "  validation loss:\t\t0.688129\n",
      "  validation accuracy:\t\t54.44 %\n",
      "  training loss:\t\t0.683710\n",
      "  validation loss:\t\t0.683909\n",
      "  validation accuracy:\t\t55.33 %\n",
      "  training loss:\t\t0.679263\n",
      "  validation loss:\t\t0.675594\n",
      "  validation accuracy:\t\t59.33 %\n",
      "  training loss:\t\t0.672542\n",
      "  validation loss:\t\t0.672839\n",
      "  validation accuracy:\t\t59.33 %\n",
      "  training loss:\t\t0.673365\n",
      "  validation loss:\t\t0.694182\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691662\n",
      "  validation loss:\t\t0.693907\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.691754\n",
      "  validation loss:\t\t0.689458\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.690984\n",
      "  validation loss:\t\t0.689205\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.690365\n",
      "  validation loss:\t\t0.688134\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.689261\n",
      "  validation loss:\t\t0.687719\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.689113\n",
      "  validation loss:\t\t0.687060\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.687384\n",
      "  validation loss:\t\t0.685460\n",
      "  validation accuracy:\t\t54.44 %\n",
      "  training loss:\t\t0.686988\n",
      "  validation loss:\t\t0.683733\n",
      "  validation accuracy:\t\t55.33 %\n",
      "  training loss:\t\t0.684320\n",
      "  validation loss:\t\t0.682596\n",
      "  validation accuracy:\t\t55.11 %\n",
      "  training loss:\t\t0.681128\n",
      "  validation loss:\t\t0.679455\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.673689\n",
      "  validation loss:\t\t0.678939\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.685861\n",
      "  validation loss:\t\t0.687909\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.687778\n",
      "  validation loss:\t\t0.685883\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.686927\n",
      "  validation loss:\t\t0.685331\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.686671\n",
      "  validation loss:\t\t0.683827\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.685475\n",
      "  validation loss:\t\t0.683075\n",
      "  validation accuracy:\t\t54.89 %\n",
      "  training loss:\t\t0.683070\n",
      "  validation loss:\t\t0.681603\n",
      "  validation accuracy:\t\t54.89 %\n",
      "  training loss:\t\t0.681640\n",
      "  validation loss:\t\t0.678771\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.678782\n",
      "  validation loss:\t\t0.673996\n",
      "  validation accuracy:\t\t57.11 %\n",
      "  training loss:\t\t0.666606\n",
      "  validation loss:\t\t0.659738\n",
      "  validation accuracy:\t\t58.44 %\n",
      "  training loss:\t\t0.699335\n",
      "  validation loss:\t\t0.695700\n",
      "  validation accuracy:\t\t50.22 %\n",
      "  training loss:\t\t0.694497\n",
      "  validation loss:\t\t0.691644\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.693267\n",
      "  validation loss:\t\t0.691738\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.693076\n",
      "  validation loss:\t\t0.692325\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.694118\n",
      "  validation loss:\t\t0.692414\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.692613\n",
      "  validation loss:\t\t0.691165\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.692931\n",
      "  validation loss:\t\t0.691069\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.692761\n",
      "  validation loss:\t\t0.691576\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.692207\n",
      "  validation loss:\t\t0.691373\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.691660\n",
      "  validation loss:\t\t0.689570\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691517\n",
      "  validation loss:\t\t0.688774\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.689914\n",
      "  validation loss:\t\t0.688038\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.689654\n",
      "  validation loss:\t\t0.686552\n",
      "  validation accuracy:\t\t53.11 %\n",
      "  training loss:\t\t0.685465\n",
      "  validation loss:\t\t0.684075\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.683111\n",
      "  validation loss:\t\t0.676012\n",
      "  validation accuracy:\t\t57.33 %\n",
      "  training loss:\t\t0.673347\n",
      "  validation loss:\t\t0.680808\n",
      "  validation accuracy:\t\t55.56 %\n",
      "  training loss:\t\t0.678851\n",
      "  validation loss:\t\t0.690540\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.692919\n",
      "  validation loss:\t\t0.692465\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.693159\n",
      "  validation loss:\t\t0.690689\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.692517\n",
      "  validation loss:\t\t0.690777\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.692531\n",
      "  validation loss:\t\t0.690422\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.691987\n",
      "  validation loss:\t\t0.689788\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.692361\n",
      "  validation loss:\t\t0.689782\n",
      "  validation accuracy:\t\t51.78 %\n",
      "  training loss:\t\t0.691640\n",
      "  validation loss:\t\t0.688283\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.690869\n",
      "  validation loss:\t\t0.688368\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.690705\n",
      "  validation loss:\t\t0.687833\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.688363\n",
      "  validation loss:\t\t0.686001\n",
      "  validation accuracy:\t\t54.00 %\n",
      "  training loss:\t\t0.686871\n",
      "  validation loss:\t\t0.684942\n",
      "  validation accuracy:\t\t54.00 %\n",
      "  training loss:\t\t0.687004\n",
      "  validation loss:\t\t0.683540\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.684970\n",
      "  validation loss:\t\t0.679325\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.682658\n",
      "  validation loss:\t\t0.758730\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.740635\n",
      "  validation loss:\t\t0.695926\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.693304\n",
      "  validation loss:\t\t0.691288\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.688577\n",
      "  validation loss:\t\t0.687909\n",
      "  validation accuracy:\t\t54.00 %\n",
      "  training loss:\t\t0.687771\n",
      "  validation loss:\t\t0.692233\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.691586\n",
      "  validation loss:\t\t0.691962\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.692085\n",
      "  validation loss:\t\t0.691791\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.691983\n",
      "  validation loss:\t\t0.691714\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.692262\n",
      "  validation loss:\t\t0.690983\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.692258\n",
      "  validation loss:\t\t0.692108\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.691585\n",
      "  validation loss:\t\t0.691159\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.691064\n",
      "  validation loss:\t\t0.691040\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.691807\n",
      "  validation loss:\t\t0.691180\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.690069\n",
      "  validation loss:\t\t0.690181\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.690022\n",
      "  validation loss:\t\t0.689268\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.689991\n",
      "  validation loss:\t\t0.688668\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.688759\n",
      "  validation loss:\t\t0.688702\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.688776\n",
      "  validation loss:\t\t0.687934\n",
      "  validation accuracy:\t\t53.11 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.687122\n",
      "  validation loss:\t\t0.687048\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.686590\n",
      "  validation loss:\t\t0.685204\n",
      "  validation accuracy:\t\t54.89 %\n",
      "  training loss:\t\t0.683972\n",
      "  validation loss:\t\t0.683221\n",
      "  validation accuracy:\t\t56.22 %\n",
      "  training loss:\t\t0.679473\n",
      "  validation loss:\t\t0.662917\n",
      "  validation accuracy:\t\t66.67 %\n",
      "  training loss:\t\t0.683477\n",
      "  validation loss:\t\t0.689488\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.688483\n",
      "  validation loss:\t\t0.687254\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.687037\n",
      "  validation loss:\t\t0.685282\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.685411\n",
      "  validation loss:\t\t0.684659\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.683561\n",
      "  validation loss:\t\t0.682489\n",
      "  validation accuracy:\t\t55.56 %\n",
      "  training loss:\t\t0.681395\n",
      "  validation loss:\t\t0.678139\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.672069\n",
      "  validation loss:\t\t0.653400\n",
      "  validation accuracy:\t\t65.11 %\n",
      "  training loss:\t\t0.699964\n",
      "  validation loss:\t\t0.689038\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.687195\n",
      "  validation loss:\t\t0.685552\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.685690\n",
      "  validation loss:\t\t0.683152\n",
      "  validation accuracy:\t\t55.56 %\n",
      "  training loss:\t\t0.683862\n",
      "  validation loss:\t\t0.681355\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.680998\n",
      "  validation loss:\t\t0.677527\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.670161\n",
      "  validation loss:\t\t0.673219\n",
      "  validation accuracy:\t\t58.89 %\n",
      "  training loss:\t\t0.683272\n",
      "  validation loss:\t\t0.665093\n",
      "  validation accuracy:\t\t60.00 %\n",
      "  training loss:\t\t0.715401\n",
      "  validation loss:\t\t0.787811\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.743887\n",
      "  validation loss:\t\t0.696588\n",
      "  validation accuracy:\t\t51.33 %\n",
      "  training loss:\t\t0.698762\n",
      "  validation loss:\t\t0.697240\n",
      "  validation accuracy:\t\t48.67 %\n",
      "  training loss:\t\t0.694658\n",
      "  validation loss:\t\t0.693239\n",
      "  validation accuracy:\t\t48.67 %\n",
      "  training loss:\t\t0.691538\n",
      "  validation loss:\t\t0.691697\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.690542\n",
      "  validation loss:\t\t0.690244\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.689452\n",
      "  validation loss:\t\t0.688922\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.686868\n",
      "  validation loss:\t\t0.682681\n",
      "  validation accuracy:\t\t60.22 %\n",
      "  training loss:\t\t0.681834\n",
      "  validation loss:\t\t0.678513\n",
      "  validation accuracy:\t\t61.78 %\n",
      "  training loss:\t\t0.689245\n",
      "  validation loss:\t\t0.696389\n",
      "  validation accuracy:\t\t48.89 %\n",
      "  training loss:\t\t0.692882\n",
      "  validation loss:\t\t0.693888\n",
      "  validation accuracy:\t\t49.33 %\n",
      "  training loss:\t\t0.692247\n",
      "  validation loss:\t\t0.692649\n",
      "  validation accuracy:\t\t51.11 %\n",
      "  training loss:\t\t0.692339\n",
      "  validation loss:\t\t0.692236\n",
      "  validation accuracy:\t\t52.44 %\n",
      "  training loss:\t\t0.692211\n",
      "  validation loss:\t\t0.691903\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.692302\n",
      "  validation loss:\t\t0.692114\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.692092\n",
      "  validation loss:\t\t0.692031\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691961\n",
      "  validation loss:\t\t0.692013\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691380\n",
      "  validation loss:\t\t0.691791\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691959\n",
      "  validation loss:\t\t0.692117\n",
      "  validation accuracy:\t\t51.56 %\n",
      "  training loss:\t\t0.691509\n",
      "  validation loss:\t\t0.691641\n",
      "  validation accuracy:\t\t52.67 %\n",
      "  training loss:\t\t0.691141\n",
      "  validation loss:\t\t0.690860\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.691064\n",
      "  validation loss:\t\t0.690884\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.691015\n",
      "  validation loss:\t\t0.690034\n",
      "  validation accuracy:\t\t54.00 %\n",
      "  training loss:\t\t0.690014\n",
      "  validation loss:\t\t0.690732\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.689693\n",
      "  validation loss:\t\t0.690600\n",
      "  validation accuracy:\t\t52.89 %\n",
      "  training loss:\t\t0.689149\n",
      "  validation loss:\t\t0.689057\n",
      "  validation accuracy:\t\t54.00 %\n",
      "  training loss:\t\t0.688591\n",
      "  validation loss:\t\t0.688250\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.688135\n",
      "  validation loss:\t\t0.687748\n",
      "  validation accuracy:\t\t54.67 %\n",
      "  training loss:\t\t0.687090\n",
      "  validation loss:\t\t0.686172\n",
      "  validation accuracy:\t\t55.33 %\n",
      "  training loss:\t\t0.686279\n",
      "  validation loss:\t\t0.683820\n",
      "  validation accuracy:\t\t56.00 %\n",
      "  training loss:\t\t0.683867\n",
      "  validation loss:\t\t0.682494\n",
      "  validation accuracy:\t\t56.22 %\n",
      "  training loss:\t\t0.679266\n",
      "  validation loss:\t\t0.675377\n",
      "  validation accuracy:\t\t59.56 %\n",
      "  training loss:\t\t0.675027\n",
      "  validation loss:\t\t0.681808\n",
      "  validation accuracy:\t\t56.22 %\n",
      "  training loss:\t\t0.681377\n",
      "  validation loss:\t\t0.684883\n",
      "  validation accuracy:\t\t55.33 %\n",
      "  training loss:\t\t0.681063\n",
      "  validation loss:\t\t0.679189\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.674227\n",
      "  validation loss:\t\t0.662292\n",
      "  validation accuracy:\t\t67.11 %\n",
      "  training loss:\t\t0.677128\n",
      "  validation loss:\t\t0.684072\n",
      "  validation accuracy:\t\t55.56 %\n",
      "  training loss:\t\t0.682632\n",
      "  validation loss:\t\t0.679974\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.677766\n",
      "  validation loss:\t\t0.674742\n",
      "  validation accuracy:\t\t58.44 %\n",
      "  training loss:\t\t0.665734\n",
      "  validation loss:\t\t0.673300\n",
      "  validation accuracy:\t\t58.44 %\n",
      "  training loss:\t\t0.677387\n",
      "  validation loss:\t\t0.678291\n",
      "  validation accuracy:\t\t56.44 %\n",
      "  training loss:\t\t0.674584\n",
      "  validation loss:\t\t0.670054\n",
      "  validation accuracy:\t\t59.11 %\n",
      "  training loss:\t\t0.662054\n",
      "  validation loss:\t\t0.650507\n",
      "  validation accuracy:\t\t66.22 %\n",
      "  training loss:\t\t0.652972\n",
      "  validation loss:\t\t0.673282\n",
      "  validation accuracy:\t\t59.11 %\n",
      "  training loss:\t\t0.681695\n",
      "  validation loss:\t\t0.687759\n",
      "  validation accuracy:\t\t55.33 %\n",
      "  training loss:\t\t0.676667\n",
      "  validation loss:\t\t0.664642\n",
      "  validation accuracy:\t\t60.22 %\n",
      "  training loss:\t\t0.672297\n",
      "  validation loss:\t\t0.641864\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.659197\n",
      "  validation loss:\t\t0.632525\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.659487\n",
      "  validation loss:\t\t0.638900\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.681846\n",
      "  validation loss:\t\t0.690509\n",
      "  validation accuracy:\t\t53.56 %\n",
      "  training loss:\t\t0.683722\n",
      "  validation loss:\t\t0.681511\n",
      "  validation accuracy:\t\t54.89 %\n",
      "  training loss:\t\t0.681779\n",
      "  validation loss:\t\t0.677661\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.677209\n",
      "  validation loss:\t\t0.675298\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.675881\n",
      "  validation loss:\t\t0.670257\n",
      "  validation accuracy:\t\t58.67 %\n",
      "  training loss:\t\t0.661156\n",
      "  validation loss:\t\t0.633209\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.640265\n",
      "  validation loss:\t\t0.640651\n",
      "  validation accuracy:\t\t65.33 %\n",
      "  training loss:\t\t0.637863\n",
      "  validation loss:\t\t0.632048\n",
      "  validation accuracy:\t\t67.33 %\n",
      "  training loss:\t\t0.625585\n",
      "  validation loss:\t\t0.643512\n",
      "  validation accuracy:\t\t64.89 %\n",
      "  training loss:\t\t0.623427\n",
      "  validation loss:\t\t0.633798\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.617344\n",
      "  validation loss:\t\t0.698219\n",
      "  validation accuracy:\t\t55.33 %\n",
      "  training loss:\t\t0.617839\n",
      "  validation loss:\t\t0.615239\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.612555\n",
      "  validation loss:\t\t0.616273\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.623991\n",
      "  validation loss:\t\t0.602716\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.613142\n",
      "  validation loss:\t\t0.589781\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.632735\n",
      "  validation loss:\t\t0.620743\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.615991\n",
      "  validation loss:\t\t0.612132\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.605882\n",
      "  validation loss:\t\t0.595554\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.593655\n",
      "  validation loss:\t\t0.581286\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.604831\n",
      "  validation loss:\t\t0.606361\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.602464\n",
      "  validation loss:\t\t0.586534\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.602757\n",
      "  validation loss:\t\t0.573547\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.639264\n",
      "  validation loss:\t\t0.609632\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.622129\n",
      "  validation loss:\t\t0.615831\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.612022\n",
      "  validation loss:\t\t0.604675\n",
      "  validation accuracy:\t\t69.11 %\n",
      "  training loss:\t\t0.592074\n",
      "  validation loss:\t\t0.579054\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.687225\n",
      "  validation loss:\t\t0.743692\n",
      "  validation accuracy:\t\t57.56 %\n",
      "  training loss:\t\t0.666133\n",
      "  validation loss:\t\t0.668787\n",
      "  validation accuracy:\t\t61.11 %\n",
      "  training loss:\t\t0.659205\n",
      "  validation loss:\t\t0.610415\n",
      "  validation accuracy:\t\t68.89 %\n",
      "  training loss:\t\t0.609439\n",
      "  validation loss:\t\t0.587720\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.626575\n",
      "  validation loss:\t\t0.595524\n",
      "  validation accuracy:\t\t67.56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.632901\n",
      "  validation loss:\t\t0.685550\n",
      "  validation accuracy:\t\t60.00 %\n",
      "  training loss:\t\t0.623979\n",
      "  validation loss:\t\t0.595771\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.596249\n",
      "  validation loss:\t\t0.596186\n",
      "  validation accuracy:\t\t69.78 %\n",
      "  training loss:\t\t0.583112\n",
      "  validation loss:\t\t0.618165\n",
      "  validation accuracy:\t\t68.67 %\n",
      "  training loss:\t\t0.591912\n",
      "  validation loss:\t\t0.640300\n",
      "  validation accuracy:\t\t67.11 %\n",
      "  training loss:\t\t0.601127\n",
      "  validation loss:\t\t0.573122\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.578903\n",
      "  validation loss:\t\t0.592139\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.594380\n",
      "  validation loss:\t\t0.589216\n",
      "  validation accuracy:\t\t69.33 %\n",
      "  training loss:\t\t0.582059\n",
      "  validation loss:\t\t0.557398\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.607935\n",
      "  validation loss:\t\t0.605998\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.589213\n",
      "  validation loss:\t\t0.556475\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.574459\n",
      "  validation loss:\t\t0.570952\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.583331\n",
      "  validation loss:\t\t0.596704\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.587376\n",
      "  validation loss:\t\t0.552770\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.573955\n",
      "  validation loss:\t\t0.554456\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.578259\n",
      "  validation loss:\t\t0.553424\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.582368\n",
      "  validation loss:\t\t0.593260\n",
      "  validation accuracy:\t\t69.11 %\n",
      "  training loss:\t\t0.583540\n",
      "  validation loss:\t\t0.550533\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.593017\n",
      "  validation loss:\t\t0.633067\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.597677\n",
      "  validation loss:\t\t0.579244\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.588835\n",
      "  validation loss:\t\t0.551544\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.599210\n",
      "  validation loss:\t\t0.556009\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.564723\n",
      "  validation loss:\t\t0.551139\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.566738\n",
      "  validation loss:\t\t0.576883\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.584651\n",
      "  validation loss:\t\t0.613083\n",
      "  validation accuracy:\t\t69.78 %\n",
      "  training loss:\t\t0.590773\n",
      "  validation loss:\t\t0.561142\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.561209\n",
      "  validation loss:\t\t0.546404\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.567067\n",
      "  validation loss:\t\t0.605517\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.569649\n",
      "  validation loss:\t\t0.567718\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.575242\n",
      "  validation loss:\t\t0.582306\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.585603\n",
      "  validation loss:\t\t0.585436\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.569582\n",
      "  validation loss:\t\t0.580873\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.558308\n",
      "  validation loss:\t\t0.620003\n",
      "  validation accuracy:\t\t69.33 %\n",
      "  training loss:\t\t0.616705\n",
      "  validation loss:\t\t0.543593\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.566950\n",
      "  validation loss:\t\t0.551147\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.552538\n",
      "  validation loss:\t\t0.578763\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.575746\n",
      "  validation loss:\t\t0.552437\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.567046\n",
      "  validation loss:\t\t0.586579\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.551898\n",
      "  validation loss:\t\t0.541475\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.581809\n",
      "  validation loss:\t\t0.539119\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.564293\n",
      "  validation loss:\t\t0.540155\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.554958\n",
      "  validation loss:\t\t0.646204\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.567383\n",
      "  validation loss:\t\t0.535365\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.549671\n",
      "  validation loss:\t\t0.565003\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.563771\n",
      "  validation loss:\t\t0.535320\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.564976\n",
      "  validation loss:\t\t0.534234\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.591554\n",
      "  validation loss:\t\t0.551650\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.562812\n",
      "  validation loss:\t\t0.580414\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.552002\n",
      "  validation loss:\t\t0.530985\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.559004\n",
      "  validation loss:\t\t0.550988\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.554658\n",
      "  validation loss:\t\t0.536747\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.552114\n",
      "  validation loss:\t\t0.567160\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.579335\n",
      "  validation loss:\t\t0.661423\n",
      "  validation accuracy:\t\t63.78 %\n",
      "  training loss:\t\t0.578333\n",
      "  validation loss:\t\t0.534304\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.584685\n",
      "  validation loss:\t\t0.673295\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.575381\n",
      "  validation loss:\t\t0.531209\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.554433\n",
      "  validation loss:\t\t0.535991\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.553192\n",
      "  validation loss:\t\t0.545574\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.558418\n",
      "  validation loss:\t\t0.565509\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.561303\n",
      "  validation loss:\t\t0.542428\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.548127\n",
      "  validation loss:\t\t0.567069\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.546076\n",
      "  validation loss:\t\t0.596496\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.554323\n",
      "  validation loss:\t\t0.559265\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.548035\n",
      "  validation loss:\t\t0.530021\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.567055\n",
      "  validation loss:\t\t0.561824\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.583460\n",
      "  validation loss:\t\t0.684429\n",
      "  validation accuracy:\t\t60.44 %\n",
      "  training loss:\t\t0.602371\n",
      "  validation loss:\t\t0.542980\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.549072\n",
      "  validation loss:\t\t0.553679\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.551096\n",
      "  validation loss:\t\t0.527148\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.546684\n",
      "  validation loss:\t\t0.526242\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.559268\n",
      "  validation loss:\t\t0.555286\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.546410\n",
      "  validation loss:\t\t0.538075\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.542096\n",
      "  validation loss:\t\t0.526299\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.605574\n",
      "  validation loss:\t\t0.527879\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.550596\n",
      "  validation loss:\t\t0.546121\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.556241\n",
      "  validation loss:\t\t0.523356\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.543542\n",
      "  validation loss:\t\t0.542690\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.534995\n",
      "  validation loss:\t\t0.580710\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.534087\n",
      "  validation loss:\t\t0.613594\n",
      "  validation accuracy:\t\t69.78 %\n",
      "  training loss:\t\t0.551941\n",
      "  validation loss:\t\t0.528577\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.548998\n",
      "  validation loss:\t\t0.530191\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.577300\n",
      "  validation loss:\t\t0.525113\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.558291\n",
      "  validation loss:\t\t0.597977\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.546543\n",
      "  validation loss:\t\t0.531526\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.541965\n",
      "  validation loss:\t\t0.550862\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.538970\n",
      "  validation loss:\t\t0.534535\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.565337\n",
      "  validation loss:\t\t0.526565\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.546477\n",
      "  validation loss:\t\t0.518337\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.545874\n",
      "  validation loss:\t\t0.518895\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.533058\n",
      "  validation loss:\t\t0.561620\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.530814\n",
      "  validation loss:\t\t0.524006\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.533707\n",
      "  validation loss:\t\t0.629441\n",
      "  validation accuracy:\t\t68.67 %\n",
      "  training loss:\t\t0.534250\n",
      "  validation loss:\t\t0.517422\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.544956\n",
      "  validation loss:\t\t0.532052\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.541087\n",
      "  validation loss:\t\t0.518055\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.549000\n",
      "  validation loss:\t\t0.524203\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.539600\n",
      "  validation loss:\t\t0.524479\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.563863\n",
      "  validation loss:\t\t0.621177\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.597362\n",
      "  validation loss:\t\t0.523466\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.534779\n",
      "  validation loss:\t\t0.666894\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.561374\n",
      "  validation loss:\t\t0.515114\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.543080\n",
      "  validation loss:\t\t0.551812\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.546250\n",
      "  validation loss:\t\t0.565589\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.546137\n",
      "  validation loss:\t\t0.520143\n",
      "  validation accuracy:\t\t76.44 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.547550\n",
      "  validation loss:\t\t0.522856\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.556630\n",
      "  validation loss:\t\t0.525690\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.548407\n",
      "  validation loss:\t\t0.513877\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.535623\n",
      "  validation loss:\t\t0.531455\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.555301\n",
      "  validation loss:\t\t0.514369\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.541114\n",
      "  validation loss:\t\t0.516758\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.557047\n",
      "  validation loss:\t\t0.529069\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.563389\n",
      "  validation loss:\t\t0.696289\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.654429\n",
      "  validation loss:\t\t0.526758\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.553046\n",
      "  validation loss:\t\t0.557979\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.576750\n",
      "  validation loss:\t\t0.558356\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.556385\n",
      "  validation loss:\t\t0.557701\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.533022\n",
      "  validation loss:\t\t0.608471\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.551140\n",
      "  validation loss:\t\t0.533937\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.530780\n",
      "  validation loss:\t\t0.517353\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.567870\n",
      "  validation loss:\t\t0.626156\n",
      "  validation accuracy:\t\t66.22 %\n",
      "  training loss:\t\t0.536882\n",
      "  validation loss:\t\t0.541067\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.548100\n",
      "  validation loss:\t\t0.516989\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.539022\n",
      "  validation loss:\t\t0.518379\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.531151\n",
      "  validation loss:\t\t0.513529\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.558732\n",
      "  validation loss:\t\t0.517239\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.526155\n",
      "  validation loss:\t\t0.510782\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.627065\n",
      "  validation loss:\t\t0.512925\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.554488\n",
      "  validation loss:\t\t0.517960\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.550681\n",
      "  validation loss:\t\t0.523402\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.585680\n",
      "  validation loss:\t\t0.638525\n",
      "  validation accuracy:\t\t68.89 %\n",
      "  training loss:\t\t0.564839\n",
      "  validation loss:\t\t0.522358\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.551747\n",
      "  validation loss:\t\t0.515776\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.537318\n",
      "  validation loss:\t\t0.520136\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.531992\n",
      "  validation loss:\t\t0.533204\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.546829\n",
      "  validation loss:\t\t0.518180\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.542469\n",
      "  validation loss:\t\t0.522894\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.539236\n",
      "  validation loss:\t\t0.568623\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.536983\n",
      "  validation loss:\t\t0.553956\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.545446\n",
      "  validation loss:\t\t0.526023\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.566776\n",
      "  validation loss:\t\t0.650951\n",
      "  validation accuracy:\t\t68.67 %\n",
      "  training loss:\t\t0.538347\n",
      "  validation loss:\t\t0.515074\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.530587\n",
      "  validation loss:\t\t0.512207\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.526482\n",
      "  validation loss:\t\t0.510823\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.529576\n",
      "  validation loss:\t\t0.507954\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.549040\n",
      "  validation loss:\t\t0.519372\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.541343\n",
      "  validation loss:\t\t0.508788\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.557689\n",
      "  validation loss:\t\t0.523722\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.536746\n",
      "  validation loss:\t\t0.534979\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.546738\n",
      "  validation loss:\t\t0.536354\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.552769\n",
      "  validation loss:\t\t0.521662\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.571611\n",
      "  validation loss:\t\t0.597105\n",
      "  validation accuracy:\t\t66.67 %\n",
      "  training loss:\t\t0.605545\n",
      "  validation loss:\t\t0.522536\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.641261\n",
      "  validation loss:\t\t0.684925\n",
      "  validation accuracy:\t\t69.11 %\n",
      "  training loss:\t\t0.706761\n",
      "  validation loss:\t\t0.683245\n",
      "  validation accuracy:\t\t58.67 %\n",
      "  training loss:\t\t0.615981\n",
      "  validation loss:\t\t0.536660\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.580051\n",
      "  validation loss:\t\t0.531647\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.552616\n",
      "  validation loss:\t\t0.529787\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.589507\n",
      "  validation loss:\t\t0.582435\n",
      "  validation accuracy:\t\t68.67 %\n",
      "  training loss:\t\t0.556558\n",
      "  validation loss:\t\t0.528521\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.552245\n",
      "  validation loss:\t\t0.534097\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.533364\n",
      "  validation loss:\t\t0.530632\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.592387\n",
      "  validation loss:\t\t0.512957\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.544592\n",
      "  validation loss:\t\t0.671270\n",
      "  validation accuracy:\t\t62.22 %\n",
      "  training loss:\t\t0.629413\n",
      "  validation loss:\t\t0.523558\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.545896\n",
      "  validation loss:\t\t0.513038\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.553501\n",
      "  validation loss:\t\t0.547512\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.544529\n",
      "  validation loss:\t\t0.513641\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.518080\n",
      "  validation loss:\t\t0.509863\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.528768\n",
      "  validation loss:\t\t0.591951\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.545755\n",
      "  validation loss:\t\t0.522708\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.529029\n",
      "  validation loss:\t\t0.522381\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.534648\n",
      "  validation loss:\t\t0.508028\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.550916\n",
      "  validation loss:\t\t0.621123\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.535108\n",
      "  validation loss:\t\t0.573065\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.546727\n",
      "  validation loss:\t\t0.507182\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.568798\n",
      "  validation loss:\t\t0.529552\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.539658\n",
      "  validation loss:\t\t0.553269\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.546946\n",
      "  validation loss:\t\t0.509154\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.526884\n",
      "  validation loss:\t\t0.522081\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.530892\n",
      "  validation loss:\t\t0.529934\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.535477\n",
      "  validation loss:\t\t0.538206\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.548475\n",
      "  validation loss:\t\t0.548322\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.538003\n",
      "  validation loss:\t\t0.543514\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.539828\n",
      "  validation loss:\t\t0.525382\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.523216\n",
      "  validation loss:\t\t0.524660\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.552439\n",
      "  validation loss:\t\t0.508650\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.537759\n",
      "  validation loss:\t\t0.508613\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.530506\n",
      "  validation loss:\t\t0.503026\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.524081\n",
      "  validation loss:\t\t0.504320\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.524576\n",
      "  validation loss:\t\t0.510076\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.531714\n",
      "  validation loss:\t\t0.511661\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.515320\n",
      "  validation loss:\t\t0.518616\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.533301\n",
      "  validation loss:\t\t0.501414\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.511071\n",
      "  validation loss:\t\t0.660660\n",
      "  validation accuracy:\t\t64.67 %\n",
      "  training loss:\t\t0.625654\n",
      "  validation loss:\t\t0.515027\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.525387\n",
      "  validation loss:\t\t0.506192\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.530301\n",
      "  validation loss:\t\t0.501876\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.546224\n",
      "  validation loss:\t\t0.515865\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.525349\n",
      "  validation loss:\t\t0.519451\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.543057\n",
      "  validation loss:\t\t0.535989\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.518632\n",
      "  validation loss:\t\t0.502059\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.531347\n",
      "  validation loss:\t\t0.533943\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.519895\n",
      "  validation loss:\t\t0.521625\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.534578\n",
      "  validation loss:\t\t0.541012\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.530386\n",
      "  validation loss:\t\t0.506268\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.529549\n",
      "  validation loss:\t\t0.545125\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.536035\n",
      "  validation loss:\t\t0.500474\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.565600\n",
      "  validation loss:\t\t0.539806\n",
      "  validation accuracy:\t\t75.11 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.524321\n",
      "  validation loss:\t\t0.533442\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.530688\n",
      "  validation loss:\t\t0.503363\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.570787\n",
      "  validation loss:\t\t0.513357\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.543077\n",
      "  validation loss:\t\t0.517219\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.521522\n",
      "  validation loss:\t\t0.535282\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.549328\n",
      "  validation loss:\t\t0.516554\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.523476\n",
      "  validation loss:\t\t0.504589\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.530255\n",
      "  validation loss:\t\t0.500387\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.524732\n",
      "  validation loss:\t\t0.514419\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.526538\n",
      "  validation loss:\t\t0.506331\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.520534\n",
      "  validation loss:\t\t0.507495\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.526895\n",
      "  validation loss:\t\t0.501722\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.533534\n",
      "  validation loss:\t\t0.526267\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.519455\n",
      "  validation loss:\t\t0.543772\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.525426\n",
      "  validation loss:\t\t0.549777\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.518394\n",
      "  validation loss:\t\t0.539814\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.535299\n",
      "  validation loss:\t\t0.495051\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.522922\n",
      "  validation loss:\t\t0.592076\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.527315\n",
      "  validation loss:\t\t0.535010\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.576500\n",
      "  validation loss:\t\t0.567272\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.534007\n",
      "  validation loss:\t\t0.516012\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.520753\n",
      "  validation loss:\t\t0.519431\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.523539\n",
      "  validation loss:\t\t0.509673\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.524982\n",
      "  validation loss:\t\t0.540911\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.533850\n",
      "  validation loss:\t\t0.502536\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.607069\n",
      "  validation loss:\t\t0.654627\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.616484\n",
      "  validation loss:\t\t0.642273\n",
      "  validation accuracy:\t\t64.00 %\n",
      "  training loss:\t\t0.589229\n",
      "  validation loss:\t\t0.530184\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.535841\n",
      "  validation loss:\t\t0.517052\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.542724\n",
      "  validation loss:\t\t0.527281\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.536933\n",
      "  validation loss:\t\t0.501349\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.537326\n",
      "  validation loss:\t\t0.499066\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.548357\n",
      "  validation loss:\t\t0.515360\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.520555\n",
      "  validation loss:\t\t0.582910\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.549786\n",
      "  validation loss:\t\t0.521990\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.526739\n",
      "  validation loss:\t\t0.493679\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.530899\n",
      "  validation loss:\t\t0.503729\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.520015\n",
      "  validation loss:\t\t0.501231\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.556677\n",
      "  validation loss:\t\t0.622853\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.589348\n",
      "  validation loss:\t\t0.517832\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.524654\n",
      "  validation loss:\t\t0.516367\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.513899\n",
      "  validation loss:\t\t0.525228\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.531165\n",
      "  validation loss:\t\t0.510037\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.518128\n",
      "  validation loss:\t\t0.499960\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.526190\n",
      "  validation loss:\t\t0.524499\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.528329\n",
      "  validation loss:\t\t0.495301\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.526270\n",
      "  validation loss:\t\t0.495333\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.525166\n",
      "  validation loss:\t\t0.497577\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.513500\n",
      "  validation loss:\t\t0.496185\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.533779\n",
      "  validation loss:\t\t0.529816\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.526635\n",
      "  validation loss:\t\t0.499028\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.517043\n",
      "  validation loss:\t\t0.517146\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.520318\n",
      "  validation loss:\t\t0.494695\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.509636\n",
      "  validation loss:\t\t0.640265\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.536194\n",
      "  validation loss:\t\t0.508034\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.546141\n",
      "  validation loss:\t\t0.501362\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.528531\n",
      "  validation loss:\t\t0.562198\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.529172\n",
      "  validation loss:\t\t0.512965\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.515294\n",
      "  validation loss:\t\t0.496555\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.504698\n",
      "  validation loss:\t\t0.542837\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.527276\n",
      "  validation loss:\t\t0.489986\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.517857\n",
      "  validation loss:\t\t0.510873\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.534250\n",
      "  validation loss:\t\t0.492019\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.591053\n",
      "  validation loss:\t\t0.491526\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.543716\n",
      "  validation loss:\t\t0.503038\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.522589\n",
      "  validation loss:\t\t0.514275\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.517611\n",
      "  validation loss:\t\t0.521020\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.553824\n",
      "  validation loss:\t\t0.579552\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.537999\n",
      "  validation loss:\t\t0.490837\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.530401\n",
      "  validation loss:\t\t0.507812\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.519216\n",
      "  validation loss:\t\t0.505271\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.556789\n",
      "  validation loss:\t\t0.495499\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.534954\n",
      "  validation loss:\t\t0.533815\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.535582\n",
      "  validation loss:\t\t0.529404\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.514918\n",
      "  validation loss:\t\t0.494407\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.542623\n",
      "  validation loss:\t\t0.502068\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.525839\n",
      "  validation loss:\t\t0.490522\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.516639\n",
      "  validation loss:\t\t0.550205\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.519600\n",
      "  validation loss:\t\t0.628256\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.608148\n",
      "  validation loss:\t\t0.615599\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.626778\n",
      "  validation loss:\t\t0.625276\n",
      "  validation accuracy:\t\t63.78 %\n",
      "  training loss:\t\t0.575258\n",
      "  validation loss:\t\t0.524040\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.550249\n",
      "  validation loss:\t\t0.509110\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.547572\n",
      "  validation loss:\t\t0.511313\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.532480\n",
      "  validation loss:\t\t0.500243\n",
      "  validation accuracy:\t\t79.11 %\n",
      "  training loss:\t\t0.522151\n",
      "  validation loss:\t\t0.496969\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.525092\n",
      "  validation loss:\t\t0.505473\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.518234\n",
      "  validation loss:\t\t0.490683\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.517314\n",
      "  validation loss:\t\t0.537870\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.518830\n",
      "  validation loss:\t\t0.488210\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.513124\n",
      "  validation loss:\t\t0.502718\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.532469\n",
      "  validation loss:\t\t0.633499\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.531768\n",
      "  validation loss:\t\t0.501821\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.517632\n",
      "  validation loss:\t\t0.731683\n",
      "  validation accuracy:\t\t61.33 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.555449\n",
      "  validation loss:\t\t0.495613\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.536973\n",
      "  validation loss:\t\t0.489043\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.510346\n",
      "  validation loss:\t\t0.489218\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.523276\n",
      "  validation loss:\t\t0.500457\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.535364\n",
      "  validation loss:\t\t0.558488\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.520936\n",
      "  validation loss:\t\t0.610419\n",
      "  validation accuracy:\t\t68.67 %\n",
      "  training loss:\t\t0.549490\n",
      "  validation loss:\t\t0.648047\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.538683\n",
      "  validation loss:\t\t0.497437\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.535766\n",
      "  validation loss:\t\t0.598650\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.512986\n",
      "  validation loss:\t\t0.515045\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.514462\n",
      "  validation loss:\t\t0.500886\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.548578\n",
      "  validation loss:\t\t0.546042\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.559166\n",
      "  validation loss:\t\t0.571753\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.517353\n",
      "  validation loss:\t\t0.489515\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.544713\n",
      "  validation loss:\t\t0.655183\n",
      "  validation accuracy:\t\t65.56 %\n",
      "  training loss:\t\t0.595352\n",
      "  validation loss:\t\t0.572497\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.539073\n",
      "  validation loss:\t\t0.499503\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.521323\n",
      "  validation loss:\t\t0.498977\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.520582\n",
      "  validation loss:\t\t0.492546\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.524340\n",
      "  validation loss:\t\t0.511178\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.517347\n",
      "  validation loss:\t\t0.488432\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.548085\n",
      "  validation loss:\t\t0.523246\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.518396\n",
      "  validation loss:\t\t0.489587\n",
      "  validation accuracy:\t\t79.11 %\n",
      "  training loss:\t\t0.516268\n",
      "  validation loss:\t\t0.559057\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.632180\n",
      "  validation loss:\t\t0.721765\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.698783\n",
      "  validation loss:\t\t0.514474\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.515330\n",
      "  validation loss:\t\t0.620982\n",
      "  validation accuracy:\t\t65.11 %\n",
      "  training loss:\t\t0.590248\n",
      "  validation loss:\t\t0.595975\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.579113\n",
      "  validation loss:\t\t0.533338\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.519271\n",
      "  validation loss:\t\t0.503275\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.522899\n",
      "  validation loss:\t\t0.631027\n",
      "  validation accuracy:\t\t70.44 %\n",
      "  training loss:\t\t0.566780\n",
      "  validation loss:\t\t0.508369\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.535710\n",
      "  validation loss:\t\t0.493507\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.511600\n",
      "  validation loss:\t\t0.491438\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.517026\n",
      "  validation loss:\t\t0.491631\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.522727\n",
      "  validation loss:\t\t0.494765\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.524436\n",
      "  validation loss:\t\t0.498258\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.526943\n",
      "  validation loss:\t\t0.491327\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.518790\n",
      "  validation loss:\t\t0.488873\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.522291\n",
      "  validation loss:\t\t0.607924\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.536408\n",
      "  validation loss:\t\t0.501577\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.531538\n",
      "  validation loss:\t\t0.504924\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.505519\n",
      "  validation loss:\t\t0.485141\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.515727\n",
      "  validation loss:\t\t0.508189\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.532741\n",
      "  validation loss:\t\t0.540786\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.507027\n",
      "  validation loss:\t\t0.492053\n",
      "  validation accuracy:\t\t79.11 %\n",
      "  training loss:\t\t0.528421\n",
      "  validation loss:\t\t0.484703\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.522785\n",
      "  validation loss:\t\t0.513425\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.514077\n",
      "  validation loss:\t\t0.535505\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.553280\n",
      "  validation loss:\t\t0.548142\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.519692\n",
      "  validation loss:\t\t0.483696\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.524614\n",
      "  validation loss:\t\t0.499537\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.514822\n",
      "  validation loss:\t\t0.499036\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.533254\n",
      "  validation loss:\t\t0.511568\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.576285\n",
      "  validation loss:\t\t0.657767\n",
      "  validation accuracy:\t\t64.67 %\n",
      "  training loss:\t\t0.598534\n",
      "  validation loss:\t\t0.629094\n",
      "  validation accuracy:\t\t64.89 %\n",
      "  training loss:\t\t0.622343\n",
      "  validation loss:\t\t0.610346\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.601226\n",
      "  validation loss:\t\t0.531004\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.532415\n",
      "  validation loss:\t\t0.531072\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.554674\n",
      "  validation loss:\t\t0.597220\n",
      "  validation accuracy:\t\t67.78 %\n",
      "  training loss:\t\t0.539054\n",
      "  validation loss:\t\t0.492457\n",
      "  validation accuracy:\t\t79.11 %\n",
      "  training loss:\t\t0.540579\n",
      "  validation loss:\t\t0.568913\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.539667\n",
      "  validation loss:\t\t0.506612\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.523179\n",
      "  validation loss:\t\t0.507151\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.512142\n",
      "  validation loss:\t\t0.489851\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.523332\n",
      "  validation loss:\t\t0.507727\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.515881\n",
      "  validation loss:\t\t0.497779\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.527981\n",
      "  validation loss:\t\t0.508060\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.529456\n",
      "  validation loss:\t\t0.512605\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.517753\n",
      "  validation loss:\t\t0.486119\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.519468\n",
      "  validation loss:\t\t0.500230\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.514619\n",
      "  validation loss:\t\t0.590550\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.525874\n",
      "  validation loss:\t\t0.487699\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.515837\n",
      "  validation loss:\t\t0.486809\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.520086\n",
      "  validation loss:\t\t0.551223\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.507745\n",
      "  validation loss:\t\t0.481967\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.518480\n",
      "  validation loss:\t\t0.653668\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.530662\n",
      "  validation loss:\t\t0.488367\n",
      "  validation accuracy:\t\t79.11 %\n",
      "  training loss:\t\t0.526147\n",
      "  validation loss:\t\t0.501757\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.527931\n",
      "  validation loss:\t\t0.485504\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.510225\n",
      "  validation loss:\t\t0.497395\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.510522\n",
      "  validation loss:\t\t0.487760\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.504067\n",
      "  validation loss:\t\t0.524973\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.538174\n",
      "  validation loss:\t\t0.491555\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.536972\n",
      "  validation loss:\t\t0.485315\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.526801\n",
      "  validation loss:\t\t0.506786\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.561894\n",
      "  validation loss:\t\t0.517538\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.518071\n",
      "  validation loss:\t\t0.511878\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.570138\n",
      "  validation loss:\t\t0.668150\n",
      "  validation accuracy:\t\t62.67 %\n",
      "  training loss:\t\t0.671450\n",
      "  validation loss:\t\t0.730636\n",
      "  validation accuracy:\t\t62.22 %\n",
      "  training loss:\t\t0.695962\n",
      "  validation loss:\t\t0.531346\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.539246\n",
      "  validation loss:\t\t0.484966\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.508565\n",
      "  validation loss:\t\t0.481860\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.528341\n",
      "  validation loss:\t\t0.493093\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.511059\n",
      "  validation loss:\t\t0.487770\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.516651\n",
      "  validation loss:\t\t0.488207\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.506168\n",
      "  validation loss:\t\t0.587619\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.520994\n",
      "  validation loss:\t\t0.483616\n",
      "  validation accuracy:\t\t77.56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.522956\n",
      "  validation loss:\t\t0.493900\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.515198\n",
      "  validation loss:\t\t0.487262\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.514190\n",
      "  validation loss:\t\t0.524488\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.518611\n",
      "  validation loss:\t\t0.486144\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.645371\n",
      "  validation loss:\t\t0.557180\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.532421\n",
      "  validation loss:\t\t0.505902\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.521922\n",
      "  validation loss:\t\t0.503839\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.516704\n",
      "  validation loss:\t\t0.488830\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.521953\n",
      "  validation loss:\t\t0.534698\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.517811\n",
      "  validation loss:\t\t0.488801\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.582947\n",
      "  validation loss:\t\t0.562867\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.534428\n",
      "  validation loss:\t\t0.517589\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.559017\n",
      "  validation loss:\t\t0.495037\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.520575\n",
      "  validation loss:\t\t0.653391\n",
      "  validation accuracy:\t\t62.89 %\n",
      "  training loss:\t\t0.598503\n",
      "  validation loss:\t\t0.590029\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.547880\n",
      "  validation loss:\t\t0.516561\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.533269\n",
      "  validation loss:\t\t0.498993\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.512038\n",
      "  validation loss:\t\t0.484733\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.515979\n",
      "  validation loss:\t\t0.539703\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.527417\n",
      "  validation loss:\t\t0.484935\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.512324\n",
      "  validation loss:\t\t0.527140\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.514610\n",
      "  validation loss:\t\t0.658785\n",
      "  validation accuracy:\t\t67.33 %\n",
      "  training loss:\t\t0.559436\n",
      "  validation loss:\t\t0.547776\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.511911\n",
      "  validation loss:\t\t0.502749\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.507859\n",
      "  validation loss:\t\t0.473743\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.516541\n",
      "  validation loss:\t\t0.511821\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.505875\n",
      "  validation loss:\t\t0.485885\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.497128\n",
      "  validation loss:\t\t0.517088\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.513242\n",
      "  validation loss:\t\t0.486515\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.586889\n",
      "  validation loss:\t\t0.670488\n",
      "  validation accuracy:\t\t62.89 %\n",
      "  training loss:\t\t0.608482\n",
      "  validation loss:\t\t0.493449\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.533889\n",
      "  validation loss:\t\t0.504215\n",
      "  validation accuracy:\t\t79.11 %\n",
      "  training loss:\t\t0.511438\n",
      "  validation loss:\t\t0.529589\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.513508\n",
      "  validation loss:\t\t0.493376\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.579193\n",
      "  validation loss:\t\t0.537088\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.515768\n",
      "  validation loss:\t\t0.486498\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.535682\n",
      "  validation loss:\t\t0.630560\n",
      "  validation accuracy:\t\t65.33 %\n",
      "  training loss:\t\t0.618591\n",
      "  validation loss:\t\t0.595920\n",
      "  validation accuracy:\t\t67.78 %\n",
      "  training loss:\t\t0.540220\n",
      "  validation loss:\t\t0.508403\n",
      "  validation accuracy:\t\t79.11 %\n",
      "  training loss:\t\t0.521287\n",
      "  validation loss:\t\t0.486829\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.570531\n",
      "  validation loss:\t\t0.613066\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.571357\n",
      "  validation loss:\t\t0.493979\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.507460\n",
      "  validation loss:\t\t0.488405\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.517252\n",
      "  validation loss:\t\t0.506209\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.513579\n",
      "  validation loss:\t\t0.508676\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.533908\n",
      "  validation loss:\t\t0.520381\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.516482\n",
      "  validation loss:\t\t0.492069\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.512278\n",
      "  validation loss:\t\t0.479954\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.547172\n",
      "  validation loss:\t\t0.616314\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.517314\n",
      "  validation loss:\t\t0.501078\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.499397\n",
      "  validation loss:\t\t0.516870\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.506788\n",
      "  validation loss:\t\t0.481093\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.513538\n",
      "  validation loss:\t\t0.495938\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.499841\n",
      "  validation loss:\t\t0.505190\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.515932\n",
      "  validation loss:\t\t0.517792\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.522037\n",
      "  validation loss:\t\t0.482670\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.521098\n",
      "  validation loss:\t\t0.514254\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.512307\n",
      "  validation loss:\t\t0.520671\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.511709\n",
      "  validation loss:\t\t0.498248\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.538431\n",
      "  validation loss:\t\t0.591071\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.515670\n",
      "  validation loss:\t\t0.490835\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.506281\n",
      "  validation loss:\t\t0.493441\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.506638\n",
      "  validation loss:\t\t0.477725\n",
      "  validation accuracy:\t\t79.78 %\n",
      "  training loss:\t\t0.500451\n",
      "  validation loss:\t\t0.503679\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.512069\n",
      "  validation loss:\t\t0.478164\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.508646\n",
      "  validation loss:\t\t0.475932\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.555557\n",
      "  validation loss:\t\t0.485357\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.512487\n",
      "  validation loss:\t\t0.489436\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.609774\n",
      "  validation loss:\t\t0.574806\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.572539\n",
      "  validation loss:\t\t0.628693\n",
      "  validation accuracy:\t\t65.56 %\n",
      "  training loss:\t\t0.576031\n",
      "  validation loss:\t\t0.614946\n",
      "  validation accuracy:\t\t66.22 %\n",
      "  training loss:\t\t0.546684\n",
      "  validation loss:\t\t0.573215\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.532680\n",
      "  validation loss:\t\t0.507130\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.510679\n",
      "  validation loss:\t\t0.506937\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.618273\n",
      "  validation loss:\t\t0.608441\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.554005\n",
      "  validation loss:\t\t0.503032\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.513786\n",
      "  validation loss:\t\t0.492729\n",
      "  validation accuracy:\t\t79.56 %\n",
      "  training loss:\t\t0.511417\n",
      "  validation loss:\t\t0.491405\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.509465\n",
      "  validation loss:\t\t0.508208\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.510890\n",
      "  validation loss:\t\t0.525559\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.521784\n",
      "  validation loss:\t\t0.489547\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.514521\n",
      "  validation loss:\t\t0.487844\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.505328\n",
      "  validation loss:\t\t0.488409\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.532477\n",
      "  validation loss:\t\t0.498836\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.511585\n",
      "  validation loss:\t\t0.486706\n",
      "  validation accuracy:\t\t79.33 %\n",
      "  training loss:\t\t0.541955\n",
      "  validation loss:\t\t0.493176\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.552623\n",
      "  validation loss:\t\t0.498735\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.521607\n",
      "  validation loss:\t\t0.546330\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.502318\n",
      "  validation loss:\t\t0.491400\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.526014\n",
      "  validation loss:\t\t0.528558\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.507353\n",
      "  validation loss:\t\t0.485980\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.517592\n",
      "  validation loss:\t\t0.512500\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.506087\n",
      "  validation loss:\t\t0.479780\n",
      "  validation accuracy:\t\t79.78 %\n",
      "  training loss:\t\t0.507829\n",
      "  validation loss:\t\t0.508924\n",
      "  validation accuracy:\t\t78.44 %\n",
      "  training loss:\t\t0.525854\n",
      "  validation loss:\t\t0.492704\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.507180\n",
      "  validation loss:\t\t0.484988\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.519019\n",
      "  validation loss:\t\t0.575340\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.525658\n",
      "  validation loss:\t\t0.507856\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.524114\n",
      "  validation loss:\t\t0.476289\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.512340\n",
      "  validation loss:\t\t0.505932\n",
      "  validation accuracy:\t\t78.67 %\n",
      "  training loss:\t\t0.512651\n",
      "  validation loss:\t\t0.482445\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.522744\n",
      "  validation loss:\t\t0.472796\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.538983\n",
      "  validation loss:\t\t0.520500\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.512965\n",
      "  validation loss:\t\t0.487018\n",
      "  validation accuracy:\t\t78.89 %\n",
      "  training loss:\t\t0.515620\n",
      "  validation loss:\t\t0.472244\n",
      "  validation accuracy:\t\t78.22 %\n",
      "  training loss:\t\t0.516858\n",
      "  validation loss:\t\t0.478553\n",
      "  validation accuracy:\t\t79.78 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.498279\n",
      "  validation loss:\t\t0.471743\n",
      "  validation accuracy:\t\t79.33 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(700):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        for batch in iterate_minibatches(X_train, y_train, 50, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 50, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savez('model_1.npz', *lasagne.layers.get_all_param_values(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n",
      "432\n",
      "608\n",
      "516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "893"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iterate_minibatches_2(inputs, batchsize):\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt]\n",
    "        \n",
    "        \n",
    "# use trained network for predictions\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "predict_fn = theano.function([input_var], T.argmax(test_prediction, axis=1))\n",
    "\n",
    "test_data = good\n",
    "sum = 0\n",
    "for batch in iterate_minibatches_2(inputs=test_data,batchsize=1):\n",
    "        inputs = batch\n",
    "        result=predict_fn(inputs)\n",
    "        sum += result[0]\n",
    "print len(good)\n",
    "print sum\n",
    "\n",
    "test_data = bad\n",
    "sum = 0\n",
    "for batch in iterate_minibatches_2(inputs=test_data,batchsize=1):\n",
    "        inputs = batch\n",
    "        result=predict_fn(inputs)\n",
    "        sum += result[0]\n",
    "print len(bad)\n",
    "print len(bad)-sum\n",
    "494+399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
