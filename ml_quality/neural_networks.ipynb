{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sklearn\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import lasagne.regularization as reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good = open(\"../scripts/codestyle_stats/fine_res.json\", \"r\")\n",
    "bad = open(\"../scripts/codestyle_stats/shit_res.json\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_data = bad.read().replace('\\n', ' ')\n",
    "bad_dict = json.loads(bad_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_data = good.read().replace('\\n', ' ')\n",
    "good_dict = json.loads(good_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n"
     ]
    }
   ],
   "source": [
    "print len(bad_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print len(good_dict)\n",
    "print [0]*75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 82)\n"
     ]
    }
   ],
   "source": [
    "bad = []\n",
    "for i in range(0, len(bad_dict)):\n",
    "    s = []\n",
    "    if ('errors' in bad_dict[i]):\n",
    "        #print bad_dict[i]['errors']\n",
    "        s.extend(bad_dict[i]['errors'].values())\n",
    "        #print s\n",
    "    else:\n",
    "        s.extend([0]*(len(bad_dict[0]['errors'])))\n",
    "    #print s\n",
    "    #print s\n",
    "    for key, value in bad_dict[i].items():\n",
    "         if key not in ('errors', 'filename'):\n",
    "            s.append(int(value))\n",
    "    #print data\n",
    "    s =numpy.array(s) \n",
    "    bad.append(s)\n",
    "bad = numpy.array(bad)\n",
    "print bad.shape\n",
    "# for i in range(0, len(X_train)):\n",
    "#     for elem in X_train[i]:\n",
    "#         if not (isinstance( elem, int )):\n",
    "#             print i\n",
    "#             print type(elem)\n",
    "#print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 82)\n"
     ]
    }
   ],
   "source": [
    "print bad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 82)\n",
      "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  1  0 17  0  0]\n"
     ]
    }
   ],
   "source": [
    "good = []\n",
    "for i in range(0, len(bad_dict)):\n",
    "    s = []\n",
    "    if ('errors' in good_dict[i]):\n",
    "        #print bad_dict[i]['errors']\n",
    "        s.extend(numpy.array(good_dict[i]['errors'].values()))\n",
    "        #print s\n",
    "    else:\n",
    "        s.extend([0]*(len(bad_dict[0]['errors'])))\n",
    "    #print s\n",
    "    #print s\n",
    "    for key, value in good_dict[i].items():\n",
    "         if key not in ('errors', 'filename'):\n",
    "            s.append(int(value))\n",
    "            #print data\n",
    "    s = numpy.array(s)\n",
    "    good.append(s)\n",
    "good = numpy.array(good)\n",
    "print good.shape\n",
    "print good[0]\n",
    "    #print s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1216, 82)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "X_train.extend(good)\n",
    "X_train.extend(bad)\n",
    "X_train = numpy.array(X_train)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = numpy.array([1]*len(bad_dict) + [0]* len(bad_dict), dtype=numpy.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 82)\n",
      "(487, 82)\n",
      "(729,)\n",
      "(487,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.4)\n",
    "for s in (X_train, X_val, y_train, y_val):\n",
    "    print(s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729,)\n"
     ]
    }
   ],
   "source": [
    "print numpy.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(729, 82)\n"
     ]
    }
   ],
   "source": [
    "print numpy.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network(input_var=None):\n",
    "    l_in = lasagne.layers.InputLayer(shape=(None, 82),\n",
    "                                     input_var=input_var)\n",
    "    l_hid = lasagne.layers.DenseLayer(l_in, num_units=82, \n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                       W=lasagne.init.GlorotUniform())\n",
    "    l_hid2 = lasagne.layers.DenseLayer(l_hid, num_units=41, \n",
    "                                       nonlinearity=lasagne.nonlinearities.rectify,\n",
    "                                       W=lasagne.init.GlorotUniform())\n",
    "    l_hid3 = lasagne.layers.DenseLayer(l_hid2, num_units=20, \n",
    "                                       nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                       W=lasagne.init.GlorotUniform())\n",
    "    l_out = lasagne.layers.DenseLayer(l_hid3, num_units=2, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    return l_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    #print inputs\n",
    "    #print targets\n",
    "    if shuffle:\n",
    "        indices = numpy.arange(len(inputs))\n",
    "        numpy.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.matrix('inputs')\n",
    "target_var = T.ivector('targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = build_network(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lasagne.layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params,\n",
    "                                            learning_rate=0.01,\n",
    "                                            momentum=0.9)\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(\n",
    "                                                    test_prediction,\n",
    "                                                    target_var)\n",
    "test_loss = test_loss.mean()\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var),\n",
    "                      dtype=theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.691700\n",
      "  validation loss:\t\t0.689306\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.714238\n",
      "  validation loss:\t\t0.750160\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.709289\n",
      "  validation loss:\t\t0.701812\n",
      "  validation accuracy:\t\t42.67 %\n",
      "  training loss:\t\t0.696875\n",
      "  validation loss:\t\t0.695194\n",
      "  validation accuracy:\t\t53.11 %\n",
      "  training loss:\t\t0.696305\n",
      "  validation loss:\t\t0.695363\n",
      "  validation accuracy:\t\t41.11 %\n",
      "  training loss:\t\t0.695220\n",
      "  validation loss:\t\t0.696867\n",
      "  validation accuracy:\t\t43.78 %\n",
      "  training loss:\t\t0.694738\n",
      "  validation loss:\t\t0.697007\n",
      "  validation accuracy:\t\t45.78 %\n",
      "  training loss:\t\t0.694700\n",
      "  validation loss:\t\t0.694902\n",
      "  validation accuracy:\t\t43.78 %\n",
      "  training loss:\t\t0.693692\n",
      "  validation loss:\t\t0.696415\n",
      "  validation accuracy:\t\t46.67 %\n",
      "  training loss:\t\t0.694240\n",
      "  validation loss:\t\t0.695727\n",
      "  validation accuracy:\t\t46.67 %\n",
      "  training loss:\t\t0.693773\n",
      "  validation loss:\t\t0.695416\n",
      "  validation accuracy:\t\t46.67 %\n",
      "  training loss:\t\t0.693244\n",
      "  validation loss:\t\t0.695340\n",
      "  validation accuracy:\t\t46.44 %\n",
      "  training loss:\t\t0.693790\n",
      "  validation loss:\t\t0.693881\n",
      "  validation accuracy:\t\t46.67 %\n",
      "  training loss:\t\t0.693090\n",
      "  validation loss:\t\t0.695400\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692840\n",
      "  validation loss:\t\t0.694581\n",
      "  validation accuracy:\t\t46.67 %\n",
      "  training loss:\t\t0.693183\n",
      "  validation loss:\t\t0.694358\n",
      "  validation accuracy:\t\t46.67 %\n",
      "  training loss:\t\t0.692642\n",
      "  validation loss:\t\t0.693514\n",
      "  validation accuracy:\t\t46.67 %\n",
      "  training loss:\t\t0.692490\n",
      "  validation loss:\t\t0.693050\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692059\n",
      "  validation loss:\t\t0.694001\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.691785\n",
      "  validation loss:\t\t0.694876\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692099\n",
      "  validation loss:\t\t0.694303\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.691196\n",
      "  validation loss:\t\t0.693669\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.691198\n",
      "  validation loss:\t\t0.692470\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.690719\n",
      "  validation loss:\t\t0.692572\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.689850\n",
      "  validation loss:\t\t0.693594\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.689200\n",
      "  validation loss:\t\t0.692926\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.689581\n",
      "  validation loss:\t\t0.690236\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.687731\n",
      "  validation loss:\t\t0.686759\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.686562\n",
      "  validation loss:\t\t0.684588\n",
      "  validation accuracy:\t\t63.11 %\n",
      "  training loss:\t\t0.683418\n",
      "  validation loss:\t\t0.686431\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.687623\n",
      "  validation loss:\t\t0.687414\n",
      "  validation accuracy:\t\t60.00 %\n",
      "  training loss:\t\t0.688532\n",
      "  validation loss:\t\t0.687236\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.686647\n",
      "  validation loss:\t\t0.685027\n",
      "  validation accuracy:\t\t63.11 %\n",
      "  training loss:\t\t0.690453\n",
      "  validation loss:\t\t0.691594\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692312\n",
      "  validation loss:\t\t0.692608\n",
      "  validation accuracy:\t\t56.67 %\n",
      "  training loss:\t\t0.693295\n",
      "  validation loss:\t\t0.694696\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692478\n",
      "  validation loss:\t\t0.694664\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.693095\n",
      "  validation loss:\t\t0.694976\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692678\n",
      "  validation loss:\t\t0.695381\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692533\n",
      "  validation loss:\t\t0.695398\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692806\n",
      "  validation loss:\t\t0.696165\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692505\n",
      "  validation loss:\t\t0.694512\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692596\n",
      "  validation loss:\t\t0.694618\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692510\n",
      "  validation loss:\t\t0.694176\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692132\n",
      "  validation loss:\t\t0.694175\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692275\n",
      "  validation loss:\t\t0.694108\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692151\n",
      "  validation loss:\t\t0.695334\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692026\n",
      "  validation loss:\t\t0.695069\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692367\n",
      "  validation loss:\t\t0.695079\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692072\n",
      "  validation loss:\t\t0.695797\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692656\n",
      "  validation loss:\t\t0.694063\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.693006\n",
      "  validation loss:\t\t0.694052\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692410\n",
      "  validation loss:\t\t0.692519\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.692311\n",
      "  validation loss:\t\t0.694819\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.691426\n",
      "  validation loss:\t\t0.693484\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.691812\n",
      "  validation loss:\t\t0.692331\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.690717\n",
      "  validation loss:\t\t0.693539\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.690619\n",
      "  validation loss:\t\t0.693513\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.690416\n",
      "  validation loss:\t\t0.692235\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.690464\n",
      "  validation loss:\t\t0.691589\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.689304\n",
      "  validation loss:\t\t0.690159\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.688051\n",
      "  validation loss:\t\t0.689633\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.686830\n",
      "  validation loss:\t\t0.687661\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.685481\n",
      "  validation loss:\t\t0.682913\n",
      "  validation accuracy:\t\t62.44 %\n",
      "  training loss:\t\t0.678843\n",
      "  validation loss:\t\t0.674462\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.680955\n",
      "  validation loss:\t\t0.681982\n",
      "  validation accuracy:\t\t59.11 %\n",
      "  training loss:\t\t0.685584\n",
      "  validation loss:\t\t0.683443\n",
      "  validation accuracy:\t\t61.11 %\n",
      "  training loss:\t\t0.683357\n",
      "  validation loss:\t\t0.683415\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.679623\n",
      "  validation loss:\t\t0.677725\n",
      "  validation accuracy:\t\t60.89 %\n",
      "  training loss:\t\t0.670024\n",
      "  validation loss:\t\t0.667793\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.682047\n",
      "  validation loss:\t\t0.678366\n",
      "  validation accuracy:\t\t60.00 %\n",
      "  training loss:\t\t0.681795\n",
      "  validation loss:\t\t0.679047\n",
      "  validation accuracy:\t\t60.89 %\n",
      "  training loss:\t\t0.679040\n",
      "  validation loss:\t\t0.676518\n",
      "  validation accuracy:\t\t63.33 %\n",
      "  training loss:\t\t0.673051\n",
      "  validation loss:\t\t0.670216\n",
      "  validation accuracy:\t\t64.67 %\n",
      "  training loss:\t\t0.660528\n",
      "  validation loss:\t\t0.661196\n",
      "  validation accuracy:\t\t60.89 %\n",
      "  training loss:\t\t0.654522\n",
      "  validation loss:\t\t0.658837\n",
      "  validation accuracy:\t\t62.89 %\n",
      "  training loss:\t\t0.667694\n",
      "  validation loss:\t\t0.652233\n",
      "  validation accuracy:\t\t64.67 %\n",
      "  training loss:\t\t0.649827\n",
      "  validation loss:\t\t0.650637\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.641690\n",
      "  validation loss:\t\t0.649161\n",
      "  validation accuracy:\t\t63.78 %\n",
      "  training loss:\t\t0.655794\n",
      "  validation loss:\t\t0.655141\n",
      "  validation accuracy:\t\t63.56 %\n",
      "  training loss:\t\t0.637356\n",
      "  validation loss:\t\t0.644516\n",
      "  validation accuracy:\t\t65.33 %\n",
      "  training loss:\t\t0.631129\n",
      "  validation loss:\t\t0.636818\n",
      "  validation accuracy:\t\t63.33 %\n",
      "  training loss:\t\t0.655772\n",
      "  validation loss:\t\t0.646358\n",
      "  validation accuracy:\t\t63.78 %\n",
      "  training loss:\t\t0.645617\n",
      "  validation loss:\t\t0.653866\n",
      "  validation accuracy:\t\t62.67 %\n",
      "  training loss:\t\t0.631742\n",
      "  validation loss:\t\t0.643598\n",
      "  validation accuracy:\t\t63.56 %\n",
      "  training loss:\t\t0.622582\n",
      "  validation loss:\t\t0.632469\n",
      "  validation accuracy:\t\t64.00 %\n",
      "  training loss:\t\t0.620378\n",
      "  validation loss:\t\t0.626490\n",
      "  validation accuracy:\t\t66.89 %\n",
      "  training loss:\t\t0.618166\n",
      "  validation loss:\t\t0.622358\n",
      "  validation accuracy:\t\t67.33 %\n",
      "  training loss:\t\t0.611723\n",
      "  validation loss:\t\t0.631258\n",
      "  validation accuracy:\t\t66.67 %\n",
      "  training loss:\t\t0.623073\n",
      "  validation loss:\t\t0.631331\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.620575\n",
      "  validation loss:\t\t0.618201\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.602574\n",
      "  validation loss:\t\t0.614968\n",
      "  validation accuracy:\t\t67.33 %\n",
      "  training loss:\t\t0.589021\n",
      "  validation loss:\t\t0.604495\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.595162\n",
      "  validation loss:\t\t0.596118\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.602664\n",
      "  validation loss:\t\t0.609232\n",
      "  validation accuracy:\t\t68.44 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.590295\n",
      "  validation loss:\t\t0.592860\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.575355\n",
      "  validation loss:\t\t0.624923\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.607364\n",
      "  validation loss:\t\t0.596385\n",
      "  validation accuracy:\t\t66.89 %\n",
      "  training loss:\t\t0.639832\n",
      "  validation loss:\t\t0.614003\n",
      "  validation accuracy:\t\t67.78 %\n",
      "  training loss:\t\t0.592123\n",
      "  validation loss:\t\t0.608849\n",
      "  validation accuracy:\t\t68.67 %\n",
      "  training loss:\t\t0.633722\n",
      "  validation loss:\t\t0.665427\n",
      "  validation accuracy:\t\t62.44 %\n",
      "  training loss:\t\t0.711425\n",
      "  validation loss:\t\t0.646021\n",
      "  validation accuracy:\t\t63.33 %\n",
      "  training loss:\t\t0.634156\n",
      "  validation loss:\t\t0.645030\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.662286\n",
      "  validation loss:\t\t0.653508\n",
      "  validation accuracy:\t\t62.67 %\n",
      "  training loss:\t\t0.663327\n",
      "  validation loss:\t\t0.653492\n",
      "  validation accuracy:\t\t65.56 %\n",
      "  training loss:\t\t0.651433\n",
      "  validation loss:\t\t0.662454\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.632916\n",
      "  validation loss:\t\t0.643219\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.622915\n",
      "  validation loss:\t\t0.627007\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.599858\n",
      "  validation loss:\t\t0.649124\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.681970\n",
      "  validation loss:\t\t0.619582\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.604482\n",
      "  validation loss:\t\t0.620443\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.599568\n",
      "  validation loss:\t\t0.616103\n",
      "  validation accuracy:\t\t69.33 %\n",
      "  training loss:\t\t0.596425\n",
      "  validation loss:\t\t0.603835\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.625637\n",
      "  validation loss:\t\t0.636120\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.614144\n",
      "  validation loss:\t\t0.623558\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.613697\n",
      "  validation loss:\t\t0.653076\n",
      "  validation accuracy:\t\t63.33 %\n",
      "  training loss:\t\t0.666241\n",
      "  validation loss:\t\t0.641786\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.697199\n",
      "  validation loss:\t\t0.673731\n",
      "  validation accuracy:\t\t59.33 %\n",
      "  training loss:\t\t0.678742\n",
      "  validation loss:\t\t0.675269\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.675325\n",
      "  validation loss:\t\t0.678206\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.673763\n",
      "  validation loss:\t\t0.673072\n",
      "  validation accuracy:\t\t62.67 %\n",
      "  training loss:\t\t0.675504\n",
      "  validation loss:\t\t0.666498\n",
      "  validation accuracy:\t\t61.78 %\n",
      "  training loss:\t\t0.669648\n",
      "  validation loss:\t\t0.664350\n",
      "  validation accuracy:\t\t63.33 %\n",
      "  training loss:\t\t0.662521\n",
      "  validation loss:\t\t0.656675\n",
      "  validation accuracy:\t\t66.22 %\n",
      "  training loss:\t\t0.647997\n",
      "  validation loss:\t\t0.651306\n",
      "  validation accuracy:\t\t63.56 %\n",
      "  training loss:\t\t0.619444\n",
      "  validation loss:\t\t0.625148\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.599204\n",
      "  validation loss:\t\t0.605492\n",
      "  validation accuracy:\t\t69.33 %\n",
      "  training loss:\t\t0.700358\n",
      "  validation loss:\t\t0.662108\n",
      "  validation accuracy:\t\t60.89 %\n",
      "  training loss:\t\t0.655803\n",
      "  validation loss:\t\t0.674091\n",
      "  validation accuracy:\t\t58.89 %\n",
      "  training loss:\t\t0.682190\n",
      "  validation loss:\t\t0.679333\n",
      "  validation accuracy:\t\t57.78 %\n",
      "  training loss:\t\t0.684939\n",
      "  validation loss:\t\t0.685434\n",
      "  validation accuracy:\t\t58.67 %\n",
      "  training loss:\t\t0.682792\n",
      "  validation loss:\t\t0.688253\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.682484\n",
      "  validation loss:\t\t0.685617\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.681522\n",
      "  validation loss:\t\t0.684479\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.680649\n",
      "  validation loss:\t\t0.681275\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.679910\n",
      "  validation loss:\t\t0.676837\n",
      "  validation accuracy:\t\t61.11 %\n",
      "  training loss:\t\t0.677905\n",
      "  validation loss:\t\t0.675094\n",
      "  validation accuracy:\t\t60.22 %\n",
      "  training loss:\t\t0.677149\n",
      "  validation loss:\t\t0.673078\n",
      "  validation accuracy:\t\t60.22 %\n",
      "  training loss:\t\t0.676326\n",
      "  validation loss:\t\t0.672778\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.673916\n",
      "  validation loss:\t\t0.668497\n",
      "  validation accuracy:\t\t61.78 %\n",
      "  training loss:\t\t0.670219\n",
      "  validation loss:\t\t0.665377\n",
      "  validation accuracy:\t\t63.33 %\n",
      "  training loss:\t\t0.657280\n",
      "  validation loss:\t\t0.664991\n",
      "  validation accuracy:\t\t65.11 %\n",
      "  training loss:\t\t0.662440\n",
      "  validation loss:\t\t0.661437\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.677348\n",
      "  validation loss:\t\t0.657983\n",
      "  validation accuracy:\t\t61.78 %\n",
      "  training loss:\t\t0.664241\n",
      "  validation loss:\t\t0.659188\n",
      "  validation accuracy:\t\t64.89 %\n",
      "  training loss:\t\t0.650414\n",
      "  validation loss:\t\t0.653473\n",
      "  validation accuracy:\t\t67.11 %\n",
      "  training loss:\t\t0.630668\n",
      "  validation loss:\t\t0.641780\n",
      "  validation accuracy:\t\t64.67 %\n",
      "  training loss:\t\t0.678466\n",
      "  validation loss:\t\t0.657309\n",
      "  validation accuracy:\t\t61.11 %\n",
      "  training loss:\t\t0.663572\n",
      "  validation loss:\t\t0.652394\n",
      "  validation accuracy:\t\t66.67 %\n",
      "  training loss:\t\t0.647266\n",
      "  validation loss:\t\t0.645591\n",
      "  validation accuracy:\t\t66.00 %\n",
      "  training loss:\t\t0.612120\n",
      "  validation loss:\t\t0.610403\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.584128\n",
      "  validation loss:\t\t0.595315\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.672728\n",
      "  validation loss:\t\t0.697313\n",
      "  validation accuracy:\t\t58.67 %\n",
      "  training loss:\t\t0.705536\n",
      "  validation loss:\t\t0.661305\n",
      "  validation accuracy:\t\t61.11 %\n",
      "  training loss:\t\t0.671952\n",
      "  validation loss:\t\t0.668912\n",
      "  validation accuracy:\t\t64.67 %\n",
      "  training loss:\t\t0.661500\n",
      "  validation loss:\t\t0.661759\n",
      "  validation accuracy:\t\t65.11 %\n",
      "  training loss:\t\t0.649165\n",
      "  validation loss:\t\t0.649377\n",
      "  validation accuracy:\t\t67.78 %\n",
      "  training loss:\t\t0.619507\n",
      "  validation loss:\t\t0.632624\n",
      "  validation accuracy:\t\t69.11 %\n",
      "  training loss:\t\t0.621325\n",
      "  validation loss:\t\t0.628247\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.593218\n",
      "  validation loss:\t\t0.607429\n",
      "  validation accuracy:\t\t69.11 %\n",
      "  training loss:\t\t0.593056\n",
      "  validation loss:\t\t0.602803\n",
      "  validation accuracy:\t\t67.11 %\n",
      "  training loss:\t\t0.585690\n",
      "  validation loss:\t\t0.652695\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.585868\n",
      "  validation loss:\t\t0.595806\n",
      "  validation accuracy:\t\t67.78 %\n",
      "  training loss:\t\t0.579713\n",
      "  validation loss:\t\t0.623403\n",
      "  validation accuracy:\t\t64.89 %\n",
      "  training loss:\t\t0.604973\n",
      "  validation loss:\t\t0.635129\n",
      "  validation accuracy:\t\t62.67 %\n",
      "  training loss:\t\t0.594066\n",
      "  validation loss:\t\t0.612572\n",
      "  validation accuracy:\t\t66.89 %\n",
      "  training loss:\t\t0.588507\n",
      "  validation loss:\t\t0.611891\n",
      "  validation accuracy:\t\t67.33 %\n",
      "  training loss:\t\t0.578283\n",
      "  validation loss:\t\t0.607900\n",
      "  validation accuracy:\t\t67.78 %\n",
      "  training loss:\t\t0.577855\n",
      "  validation loss:\t\t0.601770\n",
      "  validation accuracy:\t\t66.67 %\n",
      "  training loss:\t\t0.630348\n",
      "  validation loss:\t\t0.804524\n",
      "  validation accuracy:\t\t50.89 %\n",
      "  training loss:\t\t0.792276\n",
      "  validation loss:\t\t0.693076\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.690369\n",
      "  validation loss:\t\t0.670994\n",
      "  validation accuracy:\t\t58.89 %\n",
      "  training loss:\t\t0.679806\n",
      "  validation loss:\t\t0.681135\n",
      "  validation accuracy:\t\t59.56 %\n",
      "  training loss:\t\t0.678429\n",
      "  validation loss:\t\t0.684867\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.678751\n",
      "  validation loss:\t\t0.682715\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.677129\n",
      "  validation loss:\t\t0.675813\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.673512\n",
      "  validation loss:\t\t0.670003\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.664337\n",
      "  validation loss:\t\t0.660940\n",
      "  validation accuracy:\t\t65.56 %\n",
      "  training loss:\t\t0.679554\n",
      "  validation loss:\t\t0.661973\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.690189\n",
      "  validation loss:\t\t0.675276\n",
      "  validation accuracy:\t\t58.22 %\n",
      "  training loss:\t\t0.678651\n",
      "  validation loss:\t\t0.676990\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.676511\n",
      "  validation loss:\t\t0.677841\n",
      "  validation accuracy:\t\t62.22 %\n",
      "  training loss:\t\t0.678120\n",
      "  validation loss:\t\t0.674488\n",
      "  validation accuracy:\t\t62.22 %\n",
      "  training loss:\t\t0.671889\n",
      "  validation loss:\t\t0.670359\n",
      "  validation accuracy:\t\t63.11 %\n",
      "  training loss:\t\t0.661322\n",
      "  validation loss:\t\t0.660810\n",
      "  validation accuracy:\t\t65.56 %\n",
      "  training loss:\t\t0.690142\n",
      "  validation loss:\t\t0.948579\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.681723\n",
      "  validation loss:\t\t0.657657\n",
      "  validation accuracy:\t\t61.33 %\n",
      "  training loss:\t\t0.668894\n",
      "  validation loss:\t\t0.654613\n",
      "  validation accuracy:\t\t63.56 %\n",
      "  training loss:\t\t0.652882\n",
      "  validation loss:\t\t0.661387\n",
      "  validation accuracy:\t\t64.00 %\n",
      "  training loss:\t\t0.638783\n",
      "  validation loss:\t\t0.646065\n",
      "  validation accuracy:\t\t65.33 %\n",
      "  training loss:\t\t0.628926\n",
      "  validation loss:\t\t0.633455\n",
      "  validation accuracy:\t\t67.11 %\n",
      "  training loss:\t\t0.634065\n",
      "  validation loss:\t\t0.630432\n",
      "  validation accuracy:\t\t65.33 %\n",
      "  training loss:\t\t0.612047\n",
      "  validation loss:\t\t0.637326\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.612489\n",
      "  validation loss:\t\t0.635241\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.602666\n",
      "  validation loss:\t\t0.614336\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.597331\n",
      "  validation loss:\t\t0.606090\n",
      "  validation accuracy:\t\t65.11 %\n",
      "  training loss:\t\t0.604572\n",
      "  validation loss:\t\t0.641444\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.624190\n",
      "  validation loss:\t\t0.613419\n",
      "  validation accuracy:\t\t66.00 %\n",
      "  training loss:\t\t0.601146\n",
      "  validation loss:\t\t0.608370\n",
      "  validation accuracy:\t\t65.56 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.586177\n",
      "  validation loss:\t\t0.613882\n",
      "  validation accuracy:\t\t66.89 %\n",
      "  training loss:\t\t0.585129\n",
      "  validation loss:\t\t0.592794\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.602040\n",
      "  validation loss:\t\t0.605974\n",
      "  validation accuracy:\t\t66.44 %\n",
      "  training loss:\t\t0.590277\n",
      "  validation loss:\t\t0.590638\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.580933\n",
      "  validation loss:\t\t0.591277\n",
      "  validation accuracy:\t\t69.78 %\n",
      "  training loss:\t\t0.574366\n",
      "  validation loss:\t\t0.572413\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.573047\n",
      "  validation loss:\t\t0.592439\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.611821\n",
      "  validation loss:\t\t0.611959\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.568233\n",
      "  validation loss:\t\t0.588536\n",
      "  validation accuracy:\t\t69.11 %\n",
      "  training loss:\t\t0.580802\n",
      "  validation loss:\t\t0.672473\n",
      "  validation accuracy:\t\t59.33 %\n",
      "  training loss:\t\t0.596560\n",
      "  validation loss:\t\t0.583098\n",
      "  validation accuracy:\t\t70.44 %\n",
      "  training loss:\t\t0.580859\n",
      "  validation loss:\t\t0.580693\n",
      "  validation accuracy:\t\t69.33 %\n",
      "  training loss:\t\t0.572979\n",
      "  validation loss:\t\t0.594692\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.674558\n",
      "  validation loss:\t\t0.619065\n",
      "  validation accuracy:\t\t65.11 %\n",
      "  training loss:\t\t0.631468\n",
      "  validation loss:\t\t0.613032\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.586854\n",
      "  validation loss:\t\t0.599560\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.571372\n",
      "  validation loss:\t\t0.601867\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.578235\n",
      "  validation loss:\t\t0.593543\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.575928\n",
      "  validation loss:\t\t0.587766\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.564401\n",
      "  validation loss:\t\t0.589720\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.565808\n",
      "  validation loss:\t\t0.621767\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.570376\n",
      "  validation loss:\t\t0.662871\n",
      "  validation accuracy:\t\t67.11 %\n",
      "  training loss:\t\t0.591219\n",
      "  validation loss:\t\t0.582859\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.582080\n",
      "  validation loss:\t\t0.676846\n",
      "  validation accuracy:\t\t58.89 %\n",
      "  training loss:\t\t0.580414\n",
      "  validation loss:\t\t0.610103\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.570804\n",
      "  validation loss:\t\t0.579809\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.578109\n",
      "  validation loss:\t\t0.575879\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.567165\n",
      "  validation loss:\t\t0.569553\n",
      "  validation accuracy:\t\t68.67 %\n",
      "  training loss:\t\t0.557400\n",
      "  validation loss:\t\t0.566278\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.576717\n",
      "  validation loss:\t\t0.595603\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.561444\n",
      "  validation loss:\t\t0.564595\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.571121\n",
      "  validation loss:\t\t0.566275\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.566069\n",
      "  validation loss:\t\t0.570380\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.568105\n",
      "  validation loss:\t\t0.576309\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.547959\n",
      "  validation loss:\t\t0.601877\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.565010\n",
      "  validation loss:\t\t0.571064\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.548874\n",
      "  validation loss:\t\t0.553703\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.585058\n",
      "  validation loss:\t\t0.569960\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.550566\n",
      "  validation loss:\t\t0.576620\n",
      "  validation accuracy:\t\t69.33 %\n",
      "  training loss:\t\t0.572153\n",
      "  validation loss:\t\t0.559740\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.536925\n",
      "  validation loss:\t\t0.554926\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.568818\n",
      "  validation loss:\t\t0.586757\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.565900\n",
      "  validation loss:\t\t0.559790\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.537824\n",
      "  validation loss:\t\t0.559972\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.542990\n",
      "  validation loss:\t\t0.622587\n",
      "  validation accuracy:\t\t63.56 %\n",
      "  training loss:\t\t0.582242\n",
      "  validation loss:\t\t0.571219\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.569940\n",
      "  validation loss:\t\t0.597922\n",
      "  validation accuracy:\t\t69.33 %\n",
      "  training loss:\t\t0.593641\n",
      "  validation loss:\t\t0.615793\n",
      "  validation accuracy:\t\t66.67 %\n",
      "  training loss:\t\t0.580903\n",
      "  validation loss:\t\t0.596715\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.562206\n",
      "  validation loss:\t\t0.576842\n",
      "  validation accuracy:\t\t68.89 %\n",
      "  training loss:\t\t0.560416\n",
      "  validation loss:\t\t0.554346\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.582175\n",
      "  validation loss:\t\t0.687322\n",
      "  validation accuracy:\t\t59.78 %\n",
      "  training loss:\t\t0.582350\n",
      "  validation loss:\t\t0.641703\n",
      "  validation accuracy:\t\t63.78 %\n",
      "  training loss:\t\t0.549043\n",
      "  validation loss:\t\t0.564536\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.556642\n",
      "  validation loss:\t\t0.566042\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.550270\n",
      "  validation loss:\t\t0.564459\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.543144\n",
      "  validation loss:\t\t0.592825\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.548326\n",
      "  validation loss:\t\t0.591848\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.576027\n",
      "  validation loss:\t\t0.552541\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.555523\n",
      "  validation loss:\t\t0.550909\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.537412\n",
      "  validation loss:\t\t0.564125\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.619454\n",
      "  validation loss:\t\t0.756161\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.798028\n",
      "  validation loss:\t\t0.646844\n",
      "  validation accuracy:\t\t62.67 %\n",
      "  training loss:\t\t0.670382\n",
      "  validation loss:\t\t0.652614\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.664203\n",
      "  validation loss:\t\t0.657770\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.616389\n",
      "  validation loss:\t\t0.677768\n",
      "  validation accuracy:\t\t69.11 %\n",
      "  training loss:\t\t0.585050\n",
      "  validation loss:\t\t0.642643\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.553999\n",
      "  validation loss:\t\t0.681480\n",
      "  validation accuracy:\t\t63.33 %\n",
      "  training loss:\t\t0.562115\n",
      "  validation loss:\t\t0.563052\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.559101\n",
      "  validation loss:\t\t0.557761\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.561897\n",
      "  validation loss:\t\t0.554911\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.550770\n",
      "  validation loss:\t\t0.598621\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.549463\n",
      "  validation loss:\t\t0.564237\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.573987\n",
      "  validation loss:\t\t0.650391\n",
      "  validation accuracy:\t\t63.56 %\n",
      "  training loss:\t\t0.568590\n",
      "  validation loss:\t\t0.578730\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.575927\n",
      "  validation loss:\t\t0.582864\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.578437\n",
      "  validation loss:\t\t0.711262\n",
      "  validation accuracy:\t\t58.89 %\n",
      "  training loss:\t\t0.574616\n",
      "  validation loss:\t\t0.560343\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.534734\n",
      "  validation loss:\t\t0.557891\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.552574\n",
      "  validation loss:\t\t0.767685\n",
      "  validation accuracy:\t\t53.33 %\n",
      "  training loss:\t\t0.714608\n",
      "  validation loss:\t\t0.562529\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.581512\n",
      "  validation loss:\t\t0.593057\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.636758\n",
      "  validation loss:\t\t0.710642\n",
      "  validation accuracy:\t\t54.89 %\n",
      "  training loss:\t\t0.718816\n",
      "  validation loss:\t\t0.731697\n",
      "  validation accuracy:\t\t49.33 %\n",
      "  training loss:\t\t0.680952\n",
      "  validation loss:\t\t0.563488\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.565981\n",
      "  validation loss:\t\t0.580761\n",
      "  validation accuracy:\t\t70.44 %\n",
      "  training loss:\t\t0.563276\n",
      "  validation loss:\t\t0.553733\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.550272\n",
      "  validation loss:\t\t0.549822\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.541623\n",
      "  validation loss:\t\t0.548869\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.536733\n",
      "  validation loss:\t\t0.565407\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.552991\n",
      "  validation loss:\t\t0.549090\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.538765\n",
      "  validation loss:\t\t0.553186\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.534032\n",
      "  validation loss:\t\t0.571185\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.549098\n",
      "  validation loss:\t\t0.573861\n",
      "  validation accuracy:\t\t72.44 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.535660\n",
      "  validation loss:\t\t0.573599\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.565892\n",
      "  validation loss:\t\t0.551732\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.520200\n",
      "  validation loss:\t\t0.547381\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.524348\n",
      "  validation loss:\t\t0.585630\n",
      "  validation accuracy:\t\t70.44 %\n",
      "  training loss:\t\t0.550061\n",
      "  validation loss:\t\t0.604659\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.562558\n",
      "  validation loss:\t\t0.566960\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.543437\n",
      "  validation loss:\t\t0.564468\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.525721\n",
      "  validation loss:\t\t0.624245\n",
      "  validation accuracy:\t\t65.78 %\n",
      "  training loss:\t\t0.544508\n",
      "  validation loss:\t\t0.545767\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.535006\n",
      "  validation loss:\t\t0.544879\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.536573\n",
      "  validation loss:\t\t0.574836\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.540496\n",
      "  validation loss:\t\t0.557814\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.521987\n",
      "  validation loss:\t\t0.542523\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.540158\n",
      "  validation loss:\t\t0.552701\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.532764\n",
      "  validation loss:\t\t0.559205\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.522204\n",
      "  validation loss:\t\t0.586490\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.527300\n",
      "  validation loss:\t\t0.538560\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.529285\n",
      "  validation loss:\t\t0.542217\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.522908\n",
      "  validation loss:\t\t0.537337\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.530580\n",
      "  validation loss:\t\t0.539860\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.523217\n",
      "  validation loss:\t\t0.564971\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.559031\n",
      "  validation loss:\t\t0.557453\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.527049\n",
      "  validation loss:\t\t0.617781\n",
      "  validation accuracy:\t\t67.33 %\n",
      "  training loss:\t\t0.529134\n",
      "  validation loss:\t\t0.582972\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.523705\n",
      "  validation loss:\t\t0.537161\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.543289\n",
      "  validation loss:\t\t0.537105\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.514670\n",
      "  validation loss:\t\t0.560049\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.524797\n",
      "  validation loss:\t\t0.564359\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.544447\n",
      "  validation loss:\t\t0.545925\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.528242\n",
      "  validation loss:\t\t0.535988\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.541305\n",
      "  validation loss:\t\t0.745978\n",
      "  validation accuracy:\t\t61.33 %\n",
      "  training loss:\t\t0.820445\n",
      "  validation loss:\t\t0.827592\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.722199\n",
      "  validation loss:\t\t0.701215\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.688213\n",
      "  validation loss:\t\t0.686154\n",
      "  validation accuracy:\t\t55.78 %\n",
      "  training loss:\t\t0.689875\n",
      "  validation loss:\t\t0.687688\n",
      "  validation accuracy:\t\t58.00 %\n",
      "  training loss:\t\t0.687784\n",
      "  validation loss:\t\t0.689408\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.688000\n",
      "  validation loss:\t\t0.689469\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.687042\n",
      "  validation loss:\t\t0.689205\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.686563\n",
      "  validation loss:\t\t0.688073\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.685735\n",
      "  validation loss:\t\t0.688984\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.685613\n",
      "  validation loss:\t\t0.688791\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.685884\n",
      "  validation loss:\t\t0.687310\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.683717\n",
      "  validation loss:\t\t0.683571\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.684539\n",
      "  validation loss:\t\t0.680855\n",
      "  validation accuracy:\t\t60.22 %\n",
      "  training loss:\t\t0.684014\n",
      "  validation loss:\t\t0.681807\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.682829\n",
      "  validation loss:\t\t0.679577\n",
      "  validation accuracy:\t\t62.00 %\n",
      "  training loss:\t\t0.682005\n",
      "  validation loss:\t\t0.677849\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.679885\n",
      "  validation loss:\t\t0.673986\n",
      "  validation accuracy:\t\t61.56 %\n",
      "  training loss:\t\t0.677157\n",
      "  validation loss:\t\t0.669755\n",
      "  validation accuracy:\t\t62.89 %\n",
      "  training loss:\t\t0.670349\n",
      "  validation loss:\t\t0.664611\n",
      "  validation accuracy:\t\t64.22 %\n",
      "  training loss:\t\t0.657372\n",
      "  validation loss:\t\t0.645361\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.607539\n",
      "  validation loss:\t\t0.620770\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.562751\n",
      "  validation loss:\t\t0.585925\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.659479\n",
      "  validation loss:\t\t0.683656\n",
      "  validation accuracy:\t\t58.89 %\n",
      "  training loss:\t\t0.698841\n",
      "  validation loss:\t\t0.665098\n",
      "  validation accuracy:\t\t60.67 %\n",
      "  training loss:\t\t0.674783\n",
      "  validation loss:\t\t0.670722\n",
      "  validation accuracy:\t\t65.56 %\n",
      "  training loss:\t\t0.667775\n",
      "  validation loss:\t\t0.663477\n",
      "  validation accuracy:\t\t66.89 %\n",
      "  training loss:\t\t0.654575\n",
      "  validation loss:\t\t0.651565\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.632959\n",
      "  validation loss:\t\t0.636150\n",
      "  validation accuracy:\t\t66.00 %\n",
      "  training loss:\t\t0.606140\n",
      "  validation loss:\t\t0.612339\n",
      "  validation accuracy:\t\t69.56 %\n",
      "  training loss:\t\t0.569350\n",
      "  validation loss:\t\t0.571477\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.558039\n",
      "  validation loss:\t\t0.563012\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.549493\n",
      "  validation loss:\t\t0.589116\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.668002\n",
      "  validation loss:\t\t0.664819\n",
      "  validation accuracy:\t\t62.22 %\n",
      "  training loss:\t\t0.658247\n",
      "  validation loss:\t\t0.627121\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.612656\n",
      "  validation loss:\t\t0.617912\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.587254\n",
      "  validation loss:\t\t0.596073\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.560307\n",
      "  validation loss:\t\t0.563160\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.543525\n",
      "  validation loss:\t\t0.574978\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.540323\n",
      "  validation loss:\t\t0.567867\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.550050\n",
      "  validation loss:\t\t0.549566\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.536358\n",
      "  validation loss:\t\t0.544812\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.541954\n",
      "  validation loss:\t\t0.552265\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.547274\n",
      "  validation loss:\t\t0.562767\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.520302\n",
      "  validation loss:\t\t0.806492\n",
      "  validation accuracy:\t\t61.78 %\n",
      "  training loss:\t\t0.582049\n",
      "  validation loss:\t\t0.560077\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.526518\n",
      "  validation loss:\t\t0.535849\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.573843\n",
      "  validation loss:\t\t0.601489\n",
      "  validation accuracy:\t\t70.00 %\n",
      "  training loss:\t\t0.543998\n",
      "  validation loss:\t\t0.565865\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.536852\n",
      "  validation loss:\t\t0.548150\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.534014\n",
      "  validation loss:\t\t0.581157\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.529965\n",
      "  validation loss:\t\t0.555177\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.535239\n",
      "  validation loss:\t\t0.550870\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.530917\n",
      "  validation loss:\t\t0.570662\n",
      "  validation accuracy:\t\t70.44 %\n",
      "  training loss:\t\t0.561803\n",
      "  validation loss:\t\t0.547433\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.526382\n",
      "  validation loss:\t\t0.557868\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.529710\n",
      "  validation loss:\t\t0.568235\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.525311\n",
      "  validation loss:\t\t0.553303\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.525159\n",
      "  validation loss:\t\t0.559450\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.526757\n",
      "  validation loss:\t\t0.569499\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.532279\n",
      "  validation loss:\t\t0.548868\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.551136\n",
      "  validation loss:\t\t0.562752\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.539607\n",
      "  validation loss:\t\t0.545426\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.536774\n",
      "  validation loss:\t\t0.565038\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.528360\n",
      "  validation loss:\t\t0.554403\n",
      "  validation accuracy:\t\t74.00 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.545553\n",
      "  validation loss:\t\t0.538892\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.522231\n",
      "  validation loss:\t\t0.537929\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.524353\n",
      "  validation loss:\t\t0.567337\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.525840\n",
      "  validation loss:\t\t0.541824\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.517403\n",
      "  validation loss:\t\t0.540833\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.519358\n",
      "  validation loss:\t\t0.540111\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.525465\n",
      "  validation loss:\t\t0.587387\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.531613\n",
      "  validation loss:\t\t0.540459\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.523517\n",
      "  validation loss:\t\t0.569274\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.524151\n",
      "  validation loss:\t\t0.570281\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.522145\n",
      "  validation loss:\t\t0.554735\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.514587\n",
      "  validation loss:\t\t0.574941\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.549449\n",
      "  validation loss:\t\t0.534253\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.518910\n",
      "  validation loss:\t\t0.533988\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.531958\n",
      "  validation loss:\t\t0.532403\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.506194\n",
      "  validation loss:\t\t0.534705\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.533216\n",
      "  validation loss:\t\t0.531292\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.518915\n",
      "  validation loss:\t\t0.540451\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.528475\n",
      "  validation loss:\t\t0.531272\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.523672\n",
      "  validation loss:\t\t0.571145\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.510843\n",
      "  validation loss:\t\t0.547083\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.542692\n",
      "  validation loss:\t\t0.550250\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.515260\n",
      "  validation loss:\t\t0.529769\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.502435\n",
      "  validation loss:\t\t0.530739\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.509986\n",
      "  validation loss:\t\t0.538826\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.546893\n",
      "  validation loss:\t\t0.529868\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.558031\n",
      "  validation loss:\t\t0.562211\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.519891\n",
      "  validation loss:\t\t0.558273\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.603019\n",
      "  validation loss:\t\t0.561607\n",
      "  validation accuracy:\t\t70.89 %\n",
      "  training loss:\t\t0.567516\n",
      "  validation loss:\t\t0.538823\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.624702\n",
      "  validation loss:\t\t0.726484\n",
      "  validation accuracy:\t\t46.89 %\n",
      "  training loss:\t\t0.548622\n",
      "  validation loss:\t\t0.558855\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.625973\n",
      "  validation loss:\t\t0.545647\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.565940\n",
      "  validation loss:\t\t0.737014\n",
      "  validation accuracy:\t\t55.78 %\n",
      "  training loss:\t\t0.753134\n",
      "  validation loss:\t\t0.543745\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.708839\n",
      "  validation loss:\t\t0.769172\n",
      "  validation accuracy:\t\t48.89 %\n",
      "  training loss:\t\t0.717344\n",
      "  validation loss:\t\t0.710044\n",
      "  validation accuracy:\t\t48.67 %\n",
      "  training loss:\t\t0.687120\n",
      "  validation loss:\t\t0.681646\n",
      "  validation accuracy:\t\t50.22 %\n",
      "  training loss:\t\t0.646965\n",
      "  validation loss:\t\t0.577395\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.594326\n",
      "  validation loss:\t\t0.682964\n",
      "  validation accuracy:\t\t68.22 %\n",
      "  training loss:\t\t0.581711\n",
      "  validation loss:\t\t0.529220\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.583195\n",
      "  validation loss:\t\t0.573777\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.549003\n",
      "  validation loss:\t\t0.553531\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.532664\n",
      "  validation loss:\t\t0.554483\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.544735\n",
      "  validation loss:\t\t0.588466\n",
      "  validation accuracy:\t\t67.56 %\n",
      "  training loss:\t\t0.526306\n",
      "  validation loss:\t\t0.562295\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.537731\n",
      "  validation loss:\t\t0.540100\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.547322\n",
      "  validation loss:\t\t0.539052\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.525082\n",
      "  validation loss:\t\t0.547902\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.523212\n",
      "  validation loss:\t\t0.553909\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.526419\n",
      "  validation loss:\t\t0.537646\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.522787\n",
      "  validation loss:\t\t0.563807\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.545109\n",
      "  validation loss:\t\t0.554773\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.517136\n",
      "  validation loss:\t\t0.538840\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.515904\n",
      "  validation loss:\t\t0.542115\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.511157\n",
      "  validation loss:\t\t0.537065\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.541341\n",
      "  validation loss:\t\t0.536626\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.586843\n",
      "  validation loss:\t\t0.712379\n",
      "  validation accuracy:\t\t59.33 %\n",
      "  training loss:\t\t0.583870\n",
      "  validation loss:\t\t0.554798\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.531447\n",
      "  validation loss:\t\t0.541794\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.522999\n",
      "  validation loss:\t\t0.549723\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.518805\n",
      "  validation loss:\t\t0.534265\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.517764\n",
      "  validation loss:\t\t0.532994\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.522795\n",
      "  validation loss:\t\t0.533267\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.542864\n",
      "  validation loss:\t\t0.533036\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.513672\n",
      "  validation loss:\t\t0.536774\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.528745\n",
      "  validation loss:\t\t0.582263\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.526453\n",
      "  validation loss:\t\t0.576317\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.515187\n",
      "  validation loss:\t\t0.537581\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.512084\n",
      "  validation loss:\t\t0.530374\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.501236\n",
      "  validation loss:\t\t0.532499\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.518387\n",
      "  validation loss:\t\t0.529444\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.512491\n",
      "  validation loss:\t\t0.552599\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.512353\n",
      "  validation loss:\t\t0.537917\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.521822\n",
      "  validation loss:\t\t0.540484\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.519860\n",
      "  validation loss:\t\t0.526751\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.502741\n",
      "  validation loss:\t\t0.529901\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.505884\n",
      "  validation loss:\t\t0.527386\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.507179\n",
      "  validation loss:\t\t0.537236\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.493529\n",
      "  validation loss:\t\t0.569289\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.522355\n",
      "  validation loss:\t\t0.532511\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.512043\n",
      "  validation loss:\t\t0.671965\n",
      "  validation accuracy:\t\t66.67 %\n",
      "  training loss:\t\t0.516204\n",
      "  validation loss:\t\t0.638011\n",
      "  validation accuracy:\t\t68.44 %\n",
      "  training loss:\t\t0.703346\n",
      "  validation loss:\t\t0.564908\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.502268\n",
      "  validation loss:\t\t0.562842\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.538244\n",
      "  validation loss:\t\t0.560968\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.508061\n",
      "  validation loss:\t\t0.553489\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.705837\n",
      "  validation loss:\t\t0.786669\n",
      "  validation accuracy:\t\t55.11 %\n",
      "  training loss:\t\t0.601640\n",
      "  validation loss:\t\t0.551299\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.560975\n",
      "  validation loss:\t\t0.537914\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.532316\n",
      "  validation loss:\t\t0.537140\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.533876\n",
      "  validation loss:\t\t0.530661\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.521744\n",
      "  validation loss:\t\t0.536771\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.504738\n",
      "  validation loss:\t\t0.526917\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.511592\n",
      "  validation loss:\t\t0.528063\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.514683\n",
      "  validation loss:\t\t0.525502\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.520367\n",
      "  validation loss:\t\t0.527069\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.495271\n",
      "  validation loss:\t\t0.530118\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.516712\n",
      "  validation loss:\t\t0.558746\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.639947\n",
      "  validation loss:\t\t0.614729\n",
      "  validation accuracy:\t\t62.00 %\n",
      "  training loss:\t\t0.766785\n",
      "  validation loss:\t\t0.612380\n",
      "  validation accuracy:\t\t68.00 %\n",
      "  training loss:\t\t0.541565\n",
      "  validation loss:\t\t0.576939\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.548602\n",
      "  validation loss:\t\t0.583394\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.536185\n",
      "  validation loss:\t\t0.608574\n",
      "  validation accuracy:\t\t72.67 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.559612\n",
      "  validation loss:\t\t0.552108\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.522428\n",
      "  validation loss:\t\t0.576282\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.555183\n",
      "  validation loss:\t\t0.539708\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.520305\n",
      "  validation loss:\t\t0.544836\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.562574\n",
      "  validation loss:\t\t0.570519\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.518324\n",
      "  validation loss:\t\t0.694125\n",
      "  validation accuracy:\t\t61.78 %\n",
      "  training loss:\t\t0.634621\n",
      "  validation loss:\t\t0.535822\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.544407\n",
      "  validation loss:\t\t0.533606\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.514968\n",
      "  validation loss:\t\t0.537518\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.529173\n",
      "  validation loss:\t\t0.544026\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.511354\n",
      "  validation loss:\t\t0.534060\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.549653\n",
      "  validation loss:\t\t0.535483\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.518960\n",
      "  validation loss:\t\t0.541078\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.530808\n",
      "  validation loss:\t\t0.534765\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.506445\n",
      "  validation loss:\t\t0.534437\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.513256\n",
      "  validation loss:\t\t0.709360\n",
      "  validation accuracy:\t\t60.44 %\n",
      "  training loss:\t\t0.707046\n",
      "  validation loss:\t\t0.646585\n",
      "  validation accuracy:\t\t61.78 %\n",
      "  training loss:\t\t0.594393\n",
      "  validation loss:\t\t0.648314\n",
      "  validation accuracy:\t\t59.56 %\n",
      "  training loss:\t\t0.587526\n",
      "  validation loss:\t\t0.602877\n",
      "  validation accuracy:\t\t63.56 %\n",
      "  training loss:\t\t0.586048\n",
      "  validation loss:\t\t0.544372\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.611253\n",
      "  validation loss:\t\t0.609235\n",
      "  validation accuracy:\t\t62.89 %\n",
      "  training loss:\t\t0.605077\n",
      "  validation loss:\t\t0.676683\n",
      "  validation accuracy:\t\t55.11 %\n",
      "  training loss:\t\t0.670962\n",
      "  validation loss:\t\t0.631386\n",
      "  validation accuracy:\t\t59.78 %\n",
      "  training loss:\t\t0.571352\n",
      "  validation loss:\t\t0.539662\n",
      "  validation accuracy:\t\t71.11 %\n",
      "  training loss:\t\t0.537895\n",
      "  validation loss:\t\t0.542318\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.523614\n",
      "  validation loss:\t\t0.528294\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.516246\n",
      "  validation loss:\t\t0.530157\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.511560\n",
      "  validation loss:\t\t0.527467\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.507207\n",
      "  validation loss:\t\t0.528396\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.518200\n",
      "  validation loss:\t\t0.525838\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.515507\n",
      "  validation loss:\t\t0.532382\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.522640\n",
      "  validation loss:\t\t0.526522\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.488663\n",
      "  validation loss:\t\t0.529340\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.506110\n",
      "  validation loss:\t\t0.525855\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.512423\n",
      "  validation loss:\t\t0.537172\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.501764\n",
      "  validation loss:\t\t0.524340\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.496336\n",
      "  validation loss:\t\t0.561672\n",
      "  validation accuracy:\t\t71.56 %\n",
      "  training loss:\t\t0.521186\n",
      "  validation loss:\t\t0.533831\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.523114\n",
      "  validation loss:\t\t0.557956\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.511749\n",
      "  validation loss:\t\t0.529448\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.532238\n",
      "  validation loss:\t\t0.524402\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.512960\n",
      "  validation loss:\t\t0.528550\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.517160\n",
      "  validation loss:\t\t0.524856\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.507020\n",
      "  validation loss:\t\t0.530965\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.529280\n",
      "  validation loss:\t\t0.526514\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.496121\n",
      "  validation loss:\t\t0.534516\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.508263\n",
      "  validation loss:\t\t0.532997\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.542806\n",
      "  validation loss:\t\t0.581407\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.503636\n",
      "  validation loss:\t\t0.529362\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.510074\n",
      "  validation loss:\t\t0.562746\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.510137\n",
      "  validation loss:\t\t0.522500\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.507131\n",
      "  validation loss:\t\t0.623239\n",
      "  validation accuracy:\t\t67.33 %\n",
      "  training loss:\t\t0.528577\n",
      "  validation loss:\t\t0.546518\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.507091\n",
      "  validation loss:\t\t0.520750\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.498983\n",
      "  validation loss:\t\t0.525623\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.528497\n",
      "  validation loss:\t\t0.524936\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.514021\n",
      "  validation loss:\t\t0.519903\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.496210\n",
      "  validation loss:\t\t0.523215\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.513492\n",
      "  validation loss:\t\t0.532052\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.519424\n",
      "  validation loss:\t\t0.535097\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.496978\n",
      "  validation loss:\t\t0.522501\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.498524\n",
      "  validation loss:\t\t0.527052\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.514087\n",
      "  validation loss:\t\t0.524869\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.506428\n",
      "  validation loss:\t\t0.554448\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.517253\n",
      "  validation loss:\t\t0.517962\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.490105\n",
      "  validation loss:\t\t0.524794\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.503653\n",
      "  validation loss:\t\t0.525010\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.503539\n",
      "  validation loss:\t\t0.518889\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.493015\n",
      "  validation loss:\t\t0.520245\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.503809\n",
      "  validation loss:\t\t0.520286\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.510388\n",
      "  validation loss:\t\t0.564925\n",
      "  validation accuracy:\t\t72.22 %\n",
      "  training loss:\t\t0.502862\n",
      "  validation loss:\t\t0.517934\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.520443\n",
      "  validation loss:\t\t0.536956\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.507392\n",
      "  validation loss:\t\t0.527737\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.495739\n",
      "  validation loss:\t\t0.521703\n",
      "  validation accuracy:\t\t74.89 %\n",
      "  training loss:\t\t0.493209\n",
      "  validation loss:\t\t0.525020\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.488010\n",
      "  validation loss:\t\t0.531823\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.532801\n",
      "  validation loss:\t\t0.517778\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.508347\n",
      "  validation loss:\t\t0.517000\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.502581\n",
      "  validation loss:\t\t0.518146\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.492835\n",
      "  validation loss:\t\t0.518153\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.497376\n",
      "  validation loss:\t\t0.550295\n",
      "  validation accuracy:\t\t72.00 %\n",
      "  training loss:\t\t0.498761\n",
      "  validation loss:\t\t0.515685\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.529548\n",
      "  validation loss:\t\t0.514683\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.493702\n",
      "  validation loss:\t\t0.517058\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.492657\n",
      "  validation loss:\t\t0.517067\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.506553\n",
      "  validation loss:\t\t0.566197\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.496351\n",
      "  validation loss:\t\t0.540817\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.495260\n",
      "  validation loss:\t\t0.541844\n",
      "  validation accuracy:\t\t71.33 %\n",
      "  training loss:\t\t0.494854\n",
      "  validation loss:\t\t0.548013\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.500637\n",
      "  validation loss:\t\t0.515506\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.510447\n",
      "  validation loss:\t\t0.542356\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.503975\n",
      "  validation loss:\t\t0.515575\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.479074\n",
      "  validation loss:\t\t0.517200\n",
      "  validation accuracy:\t\t76.89 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.493914\n",
      "  validation loss:\t\t0.538752\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.498670\n",
      "  validation loss:\t\t0.517729\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.522641\n",
      "  validation loss:\t\t0.551766\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.493688\n",
      "  validation loss:\t\t0.517016\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.517228\n",
      "  validation loss:\t\t0.516866\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.514755\n",
      "  validation loss:\t\t0.525441\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.506839\n",
      "  validation loss:\t\t0.524780\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.498829\n",
      "  validation loss:\t\t0.515462\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.499212\n",
      "  validation loss:\t\t0.524064\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.485051\n",
      "  validation loss:\t\t0.514330\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.506956\n",
      "  validation loss:\t\t0.515597\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.495429\n",
      "  validation loss:\t\t0.555036\n",
      "  validation accuracy:\t\t71.78 %\n",
      "  training loss:\t\t0.510519\n",
      "  validation loss:\t\t0.524294\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.602332\n",
      "  validation loss:\t\t0.557469\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.551259\n",
      "  validation loss:\t\t0.557468\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.491560\n",
      "  validation loss:\t\t0.533744\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.502941\n",
      "  validation loss:\t\t0.513227\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.497361\n",
      "  validation loss:\t\t0.512902\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.500343\n",
      "  validation loss:\t\t0.521450\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.495844\n",
      "  validation loss:\t\t0.586151\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.516663\n",
      "  validation loss:\t\t0.514656\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.484992\n",
      "  validation loss:\t\t0.516083\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.504950\n",
      "  validation loss:\t\t0.519437\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.518703\n",
      "  validation loss:\t\t0.534102\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.491398\n",
      "  validation loss:\t\t0.516374\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.493397\n",
      "  validation loss:\t\t0.546981\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.507908\n",
      "  validation loss:\t\t0.514064\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.495288\n",
      "  validation loss:\t\t0.522343\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.493178\n",
      "  validation loss:\t\t0.514558\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.496751\n",
      "  validation loss:\t\t0.513028\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.486453\n",
      "  validation loss:\t\t0.570726\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.535181\n",
      "  validation loss:\t\t0.544313\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.497995\n",
      "  validation loss:\t\t0.533570\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.509135\n",
      "  validation loss:\t\t0.517916\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.501807\n",
      "  validation loss:\t\t0.533245\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.525176\n",
      "  validation loss:\t\t0.537831\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.515455\n",
      "  validation loss:\t\t0.536288\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.512108\n",
      "  validation loss:\t\t0.520306\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.493192\n",
      "  validation loss:\t\t0.515959\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.500442\n",
      "  validation loss:\t\t0.551753\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.509248\n",
      "  validation loss:\t\t0.519328\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.500344\n",
      "  validation loss:\t\t0.515218\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.501848\n",
      "  validation loss:\t\t0.511794\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.503541\n",
      "  validation loss:\t\t0.557299\n",
      "  validation accuracy:\t\t72.67 %\n",
      "  training loss:\t\t0.482343\n",
      "  validation loss:\t\t0.514971\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.491193\n",
      "  validation loss:\t\t0.524439\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.496974\n",
      "  validation loss:\t\t0.519697\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.492089\n",
      "  validation loss:\t\t0.512232\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.488750\n",
      "  validation loss:\t\t0.513060\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.499754\n",
      "  validation loss:\t\t0.513865\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.490168\n",
      "  validation loss:\t\t0.514236\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.486921\n",
      "  validation loss:\t\t0.512587\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.499701\n",
      "  validation loss:\t\t0.518257\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.487792\n",
      "  validation loss:\t\t0.514189\n",
      "  validation accuracy:\t\t76.22 %\n",
      "  training loss:\t\t0.497024\n",
      "  validation loss:\t\t0.513262\n",
      "  validation accuracy:\t\t75.33 %\n",
      "  training loss:\t\t0.483905\n",
      "  validation loss:\t\t0.520492\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.499961\n",
      "  validation loss:\t\t0.527401\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.500750\n",
      "  validation loss:\t\t0.662364\n",
      "  validation accuracy:\t\t65.56 %\n",
      "  training loss:\t\t0.549693\n",
      "  validation loss:\t\t0.508470\n",
      "  validation accuracy:\t\t77.11 %\n",
      "  training loss:\t\t0.487641\n",
      "  validation loss:\t\t0.536073\n",
      "  validation accuracy:\t\t73.56 %\n",
      "  training loss:\t\t0.533185\n",
      "  validation loss:\t\t0.510100\n",
      "  validation accuracy:\t\t78.00 %\n",
      "  training loss:\t\t0.508120\n",
      "  validation loss:\t\t0.641974\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.520031\n",
      "  validation loss:\t\t0.508730\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.499179\n",
      "  validation loss:\t\t0.545936\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.505859\n",
      "  validation loss:\t\t0.509804\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.560706\n",
      "  validation loss:\t\t0.517359\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.505060\n",
      "  validation loss:\t\t0.518873\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.491619\n",
      "  validation loss:\t\t0.519697\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.503981\n",
      "  validation loss:\t\t0.538922\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.513143\n",
      "  validation loss:\t\t0.553441\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.486847\n",
      "  validation loss:\t\t0.513900\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.492951\n",
      "  validation loss:\t\t0.555728\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.496101\n",
      "  validation loss:\t\t0.522325\n",
      "  validation accuracy:\t\t75.78 %\n",
      "  training loss:\t\t0.504940\n",
      "  validation loss:\t\t0.514974\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.485761\n",
      "  validation loss:\t\t0.510776\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.500280\n",
      "  validation loss:\t\t0.513077\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.496903\n",
      "  validation loss:\t\t0.510324\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.491074\n",
      "  validation loss:\t\t0.511860\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.488613\n",
      "  validation loss:\t\t0.512925\n",
      "  validation accuracy:\t\t77.78 %\n",
      "  training loss:\t\t0.554262\n",
      "  validation loss:\t\t0.520181\n",
      "  validation accuracy:\t\t74.22 %\n",
      "  training loss:\t\t0.500054\n",
      "  validation loss:\t\t0.512956\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.505489\n",
      "  validation loss:\t\t0.515910\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.487347\n",
      "  validation loss:\t\t0.512860\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.497040\n",
      "  validation loss:\t\t0.605830\n",
      "  validation accuracy:\t\t70.67 %\n",
      "  training loss:\t\t0.536155\n",
      "  validation loss:\t\t0.517331\n",
      "  validation accuracy:\t\t75.11 %\n",
      "  training loss:\t\t0.508233\n",
      "  validation loss:\t\t0.545450\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.480208\n",
      "  validation loss:\t\t0.584305\n",
      "  validation accuracy:\t\t70.22 %\n",
      "  training loss:\t\t0.586527\n",
      "  validation loss:\t\t0.599956\n",
      "  validation accuracy:\t\t72.44 %\n",
      "  training loss:\t\t0.557990\n",
      "  validation loss:\t\t0.524147\n",
      "  validation accuracy:\t\t75.56 %\n",
      "  training loss:\t\t0.490193\n",
      "  validation loss:\t\t0.544691\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.496629\n",
      "  validation loss:\t\t0.528589\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.503454\n",
      "  validation loss:\t\t0.545358\n",
      "  validation accuracy:\t\t74.00 %\n",
      "  training loss:\t\t0.502566\n",
      "  validation loss:\t\t0.512041\n",
      "  validation accuracy:\t\t76.67 %\n",
      "  training loss:\t\t0.491786\n",
      "  validation loss:\t\t0.510887\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.492447\n",
      "  validation loss:\t\t0.540403\n",
      "  validation accuracy:\t\t72.44 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  training loss:\t\t0.503677\n",
      "  validation loss:\t\t0.510287\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.485033\n",
      "  validation loss:\t\t0.510948\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.500822\n",
      "  validation loss:\t\t0.551474\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.494059\n",
      "  validation loss:\t\t0.536521\n",
      "  validation accuracy:\t\t72.89 %\n",
      "  training loss:\t\t0.527084\n",
      "  validation loss:\t\t0.518550\n",
      "  validation accuracy:\t\t76.00 %\n",
      "  training loss:\t\t0.495231\n",
      "  validation loss:\t\t0.508650\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.491232\n",
      "  validation loss:\t\t0.515433\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.483061\n",
      "  validation loss:\t\t0.509736\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.498291\n",
      "  validation loss:\t\t0.518001\n",
      "  validation accuracy:\t\t74.67 %\n",
      "  training loss:\t\t0.500616\n",
      "  validation loss:\t\t0.538607\n",
      "  validation accuracy:\t\t73.33 %\n",
      "  training loss:\t\t0.500579\n",
      "  validation loss:\t\t0.513901\n",
      "  validation accuracy:\t\t76.44 %\n",
      "  training loss:\t\t0.485761\n",
      "  validation loss:\t\t0.510953\n",
      "  validation accuracy:\t\t77.56 %\n",
      "  training loss:\t\t0.503560\n",
      "  validation loss:\t\t0.536678\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.501504\n",
      "  validation loss:\t\t0.509237\n",
      "  validation accuracy:\t\t77.33 %\n",
      "  training loss:\t\t0.498275\n",
      "  validation loss:\t\t0.527543\n",
      "  validation accuracy:\t\t73.78 %\n",
      "  training loss:\t\t0.495091\n",
      "  validation loss:\t\t0.560745\n",
      "  validation accuracy:\t\t73.11 %\n",
      "  training loss:\t\t0.491605\n",
      "  validation loss:\t\t0.510028\n",
      "  validation accuracy:\t\t76.89 %\n",
      "  training loss:\t\t0.485894\n",
      "  validation loss:\t\t0.529140\n",
      "  validation accuracy:\t\t74.44 %\n",
      "  training loss:\t\t0.505150\n",
      "  validation loss:\t\t0.528937\n",
      "  validation accuracy:\t\t73.11 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(700):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        for batch in iterate_minibatches(X_train, y_train, 50, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_val, y_val, 50, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n",
      "494\n",
      "608\n",
      "399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "893"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iterate_minibatches_2(inputs, batchsize):\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt]\n",
    "        \n",
    "        \n",
    "# use trained network for predictions\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "predict_fn = theano.function([input_var], T.argmax(test_prediction, axis=1))\n",
    "\n",
    "test_data = good\n",
    "sum = 0\n",
    "for batch in iterate_minibatches_2(inputs=test_data,batchsize=1):\n",
    "        inputs = batch\n",
    "        result=predict_fn(inputs)\n",
    "        sum += result[0]\n",
    "print len(good)\n",
    "print sum\n",
    "\n",
    "test_data = bad\n",
    "sum = 0\n",
    "for batch in iterate_minibatches_2(inputs=test_data,batchsize=1):\n",
    "        inputs = batch\n",
    "        result=predict_fn(inputs)\n",
    "        sum += result[0]\n",
    "print len(bad)\n",
    "print len(bad)-sum\n",
    "494+399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
